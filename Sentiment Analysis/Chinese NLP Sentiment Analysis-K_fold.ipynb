{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries Needed**  \n",
    "numpy  \n",
    "jieba  \n",
    "gensim  \n",
    "tensorflow  \n",
    "matplotlib  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import jieba # 结巴分词\n",
    "# gensim用来加载预训练word vector\n",
    "from gensim.models import KeyedVectors\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**预训练词向量**  \n",
    "本教程使用了北京师范大学中文信息处理研究所与中国人民大学 DBIIR 实验室的研究者开源的\"chinese-word-vectors\" github链接为：  \n",
    "https://github.com/Embedding/Chinese-Word-Vectors  \n",
    "如果你不知道word2vec是什么，我推荐以下一篇文章：  \n",
    "https://zhuanlan.zhihu.com/p/26306795  \n",
    "这里我们使用了\"chinese-word-vectors\"知乎Word + Ngram的词向量，可以从上面github链接下载，我们先加载预训练模型并进行一些简单测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用gensim加载预训练中文分词embedding\n",
    "cn_model = KeyedVectors.load_word2vec_format('../sgns.zhihu.bigram', \n",
    "                                          binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**词向量模型**  \n",
    "在这个词向量模型里，每一个词是一个索引，对应的是一个长度为300的向量，我们今天需要构建的LSTM神经网络模型并不能直接处理汉字文本，需要先进行分次并把词汇转换为词向量，步骤请参考下图，步骤的讲解会跟着代码一步一步来，如果你不知道RNN，GRU，LSTM是什么，我推荐deeplearning.ai的课程，网易公开课有免费中文字幕版，但我还是推荐有习题和练习代码部分的的coursera原版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词向量的长度为300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.459174,  0.511711, -0.510548,  0.49795 ,  0.764954, -0.871935,\n",
       "       -0.335191,  0.323417,  0.145888, -0.010004,  0.413674,  0.655862,\n",
       "       -0.239163, -0.202137,  0.285477,  0.607521, -0.295878,  0.473641,\n",
       "        0.657034,  0.209643,  0.060934,  0.341491,  0.179213, -0.928412,\n",
       "       -1.309496,  0.667487,  0.60432 , -0.215458,  0.556134,  1.013507,\n",
       "        0.236438,  0.490978, -0.324118,  0.827709, -0.633155, -0.125863,\n",
       "        0.399796,  0.295161, -0.437671,  0.012822,  0.073047,  0.891576,\n",
       "       -0.434772,  0.428342,  0.285875, -0.613697,  0.808781,  0.0556  ,\n",
       "        0.417876,  0.615605, -0.399464,  0.127042, -0.476437, -0.55382 ,\n",
       "       -1.051466, -0.185181,  0.148764,  0.363053, -0.445998, -0.281756,\n",
       "       -0.209169, -0.233683, -0.271602,  0.225867, -0.583228,  0.807539,\n",
       "        0.19152 ,  0.621448, -0.882431,  0.387011, -0.120132, -0.180161,\n",
       "        0.612972, -0.244528, -0.208375, -0.125486, -0.53498 ,  0.034153,\n",
       "        0.434322, -1.209   , -0.669831,  0.86926 ,  0.062807,  0.00136 ,\n",
       "       -0.490987,  1.006233, -0.148654, -0.53808 ,  0.287732,  0.086596,\n",
       "       -1.012924,  0.271536,  0.393067,  0.332786,  0.169949,  0.224006,\n",
       "       -0.094725,  0.192484,  0.470923,  0.040041,  0.097038,  0.264842,\n",
       "        0.113514, -0.187165, -0.12549 , -0.286106,  0.426061, -0.949105,\n",
       "        0.239119,  0.211662,  0.350254,  0.830895,  0.722272,  0.124756,\n",
       "       -0.30011 , -1.134423,  0.131681,  0.70601 , -0.69856 , -0.072104,\n",
       "        0.882228, -1.114946,  0.646431,  0.301071,  0.235678,  0.373774,\n",
       "       -0.705234, -0.500905, -0.001679,  0.421276, -0.3201  ,  0.499336,\n",
       "       -0.711488,  0.238791, -0.239356, -0.114212, -0.381005,  0.035718,\n",
       "        0.384427,  0.4644  ,  0.157076, -0.424991,  0.908941,  0.461443,\n",
       "       -0.777592,  0.094564, -0.333842,  0.489275,  0.67118 ,  0.232986,\n",
       "        0.145   , -0.55585 , -0.507243,  0.141199,  0.60463 ,  0.25184 ,\n",
       "        0.586655,  0.037703,  0.290834,  0.262902,  0.989265, -0.261652,\n",
       "        0.112659,  0.485826,  0.962114,  0.302486, -0.917113, -0.194288,\n",
       "       -0.177214,  0.038665,  0.604813,  0.411666, -0.322723,  0.197032,\n",
       "       -0.403384, -0.117017, -0.285895,  0.332513, -0.058978,  0.2061  ,\n",
       "        0.245319, -0.266601,  0.662994,  0.383771, -0.233815,  0.222569,\n",
       "       -0.165972, -0.104411, -0.298629, -0.208825, -0.585572, -0.134304,\n",
       "        0.415468, -0.693912,  0.107925, -0.135807,  0.493942, -0.762114,\n",
       "       -0.586571, -0.004091, -0.448647, -0.350258,  1.077331, -0.491937,\n",
       "        0.736153, -0.118269, -0.461594, -0.038056, -0.37572 , -0.574983,\n",
       "        0.473529,  0.290197, -0.12094 , -0.326806, -0.902393, -0.075414,\n",
       "        0.215203, -0.20115 , -0.262564,  0.724314,  0.219665,  0.739272,\n",
       "        0.165256, -0.512583,  0.61362 , -0.659283, -0.020006,  0.611113,\n",
       "       -0.344107, -0.451032, -0.015789,  0.4259  , -0.545758,  0.101261,\n",
       "       -0.407874,  0.085714, -0.674952, -0.338785,  0.17172 , -0.395423,\n",
       "       -0.41819 , -0.316986,  0.696344,  0.043525,  0.097642,  0.287649,\n",
       "        0.358968, -0.800531, -0.095637,  0.434663,  0.867621,  0.406756,\n",
       "        0.376954, -0.02042 , -0.847128, -0.050707,  0.190463, -0.045548,\n",
       "        0.886113,  0.053982, -0.025646,  0.467811, -0.306568,  0.030567,\n",
       "        0.0797  , -0.568458, -0.569607,  0.174566,  0.837526, -0.546647,\n",
       "       -0.2343  , -0.31945 ,  0.339874,  0.540164, -0.056752, -0.404088,\n",
       "        0.614905,  0.482624,  0.377635,  0.316339,  0.566559, -0.826425,\n",
       "        0.860249,  0.125008,  0.160322,  1.160516, -0.406189, -0.002516,\n",
       "        0.02794 , -0.952482, -0.469557, -0.489171,  0.94918 ,  0.154401,\n",
       "       -0.102438, -0.056282,  0.651899, -0.658786, -0.133147, -0.528431],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 由此可见每一个词都对应一个长度为300的向量\n",
    "embedding_dim = cn_model['孔子'].shape[0]\n",
    "print('词向量的长度为{}'.format(embedding_dim))\n",
    "cn_model['孔子']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37086627"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算相似度\n",
    "cn_model.similarity('老子', '我')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('我国', 0.6130719184875488),\n",
       " ('天朝', 0.5357025861740112),\n",
       " ('美国', 0.5048182010650635),\n",
       " ('中国人', 0.5000995993614197),\n",
       " ('本国', 0.4976556897163391),\n",
       " ('印度', 0.49548032879829407),\n",
       " ('日本', 0.491807758808136),\n",
       " ('国内', 0.4640890955924988),\n",
       " ('大陆', 0.4627026915550232),\n",
       " ('中华民族', 0.43461209535598755),\n",
       " ('外国', 0.43234753608703613),\n",
       " ('周边国家', 0.4288373291492462),\n",
       " ('台湾地区', 0.427590012550354),\n",
       " ('韩国', 0.42619460821151733),\n",
       " ('东亚国家', 0.42446058988571167),\n",
       " ('蒙古国', 0.42360609769821167),\n",
       " ('亚洲', 0.4225274920463562),\n",
       " ('亚洲各国', 0.4225262403488159),\n",
       " ('欧州', 0.4184926748275757),\n",
       " ('国人', 0.4143391251564026)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 找出最相近的词，余弦相似度\n",
    "cn_model.most_similar(positive=['中国'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在 孔丘 圣人 孔子 孟子 孔子 荀子 中:\n",
      "不是同一类别的词为: 圣人\n"
     ]
    }
   ],
   "source": [
    "# 找出不同的词\n",
    "test_words = '孔丘 圣人 孔子 孟子 孔子 荀子'\n",
    "test_words_result = cn_model.doesnt_match(test_words.split())\n",
    "print('在 '+test_words+' 中:\\n不是同一类别的词为: %s' %test_words_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('劈腿', 0.5849199295043945),\n",
       " ('婚外情', 0.5557921528816223),\n",
       " ('偷情', 0.5555664300918579),\n",
       " ('外遇', 0.5458645820617676),\n",
       " ('再婚', 0.5422405004501343),\n",
       " ('未婚先孕', 0.5357398986816406),\n",
       " ('隐婚', 0.5257365703582764),\n",
       " ('离婚', 0.524539053440094),\n",
       " ('马蓉', 0.5239365696907043),\n",
       " ('通奸', 0.5222055912017822)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_model.most_similar(positive=['女人','出轨'], negative=['男人'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得样本的索引，样本存放于两个文件夹中，\n",
    "# 分别为 正面评价'pos'文件夹 和 负面评价'neg'文件夹\n",
    "# 每个文件夹中有2000个txt文件，每个文件中是一例评价\n",
    "import os\n",
    "pos_txts = os.listdir('../Questionnaire Review/pos')\n",
    "neg_txts = os.listdir('../Questionnaire Review/neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总共: 989\n"
     ]
    }
   ],
   "source": [
    "print( '样本总共: '+ str(len(pos_txts) + len(neg_txts)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现在我们将所有的评价内容放置到一个list里\n",
    "\n",
    "train_texts_orig = [] # 存储所有评价，每例评价为一条string\n",
    "\n",
    "# 添加完所有样本之后，train_texts_orig为一个含有4000条文本的list\n",
    "# 其中前2000条文本为正面评价，后2000条为负面评价\n",
    "\n",
    "for i in range(len(pos_txts)):\n",
    "    with open('../Questionnaire Review/pos/'+pos_txts[i], 'r', errors='ignore') as f:\n",
    "        text = f.read().strip()\n",
    "        train_texts_orig.append(text)\n",
    "        f.close()\n",
    "for i in range(len(neg_txts)):\n",
    "    with open('../Questionnaire Review/neg/'+neg_txts[i], 'r', errors='ignore') as f:\n",
    "        text = f.read().strip()\n",
    "        train_texts_orig.append(text)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ڹݽһ',\n",
       " 'Ȥ',\n",
       " '̧ܣ˼˵ǷȷӦ',\n",
       " 'ѧϰ',\n",
       " 'ȥһηлҪһʽЬС һ¸о',\n",
       " 'ѧϰ \\uedfd',\n",
       " 'Ҫӵ٧ͺˣǻһ',\n",
       " 'Ůȥ',\n",
       " 'ѧϰ',\n",
       " 'ѧϰand',\n",
       " '',\n",
       " 'ճ\\ue8ec',\n",
       " 'ллǳĵʹ',\n",
       " '˵ лл㣬¿λ',\n",
       " 'ܺÿ',\n",
       " 'ƽȴҸ',\n",
       " 'ޱȵķḻϲŭ',\n",
       " 'ǳ׳',\n",
       " 'ۣллձؽ',\n",
       " '',\n",
       " '110',\n",
       " 'ҹ',\n",
       " '䡣',\n",
       " 'Ư',\n",
       " 'õĲҲ',\n",
       " 'ӹл',\n",
       " '',\n",
       " 'Լһ',\n",
       " '˼',\n",
       " 'лл',\n",
       " 'ѧϰŮ',\n",
       " 'Ϸ',\n",
       " 'Լϲ˺Լ\\uec2eˣξѣȻһһЩ',\n",
       " 'һȥһİĳεһ',\n",
       " 'Ϸ',\n",
       " '˭һ',\n",
       " 'ʱ',\n",
       " 'everything',\n",
       " 'һ',\n",
       " 'Ƶزģbվupף',\n",
       " 'ԣճ',\n",
       " 'úѧϰ',\n",
       " 'ԾͶԿ㼺',\n",
       " 'ѧʱ䴩',\n",
       " 'ճѧϰ',\n",
       " 'ϣܸıԼĿһ',\n",
       " 'ʵĶйϵѧϰᣬãЩȤ顭 ӾͶ',\n",
       " 'ǧҪˮȺ˺ìܰ\"\"\"\"Ȼ˯\"\"\"\"Ҫ',\n",
       " 'ȡ֮',\n",
       " 'ʲô',\n",
       " 'ѧϰ',\n",
       " 'ѧϰ',\n",
       " 'Ʒ˺ѿǵ\\u07b8',\n",
       " 'лл',\n",
       " 'ƽƽӹһЩССĲ۵պҸ',\n",
       " 'excitedenthusiastic',\n",
       " 'ܺ',\n",
       " 'һʼ˸Լ˸ңһֻȫ̿',\n",
       " 'лл',\n",
       " 'ұ˰æ',\n",
       " 'лмؽİ',\n",
       " 'һ\\U0003fe7a',\n",
       " 'Ȱ˵',\n",
       " '˲ôܴ\\U000b2ef9\\u07b9˲\\u0cbbڵĻӦðʵڲд\\U000b2ef9˶ܵڰ',\n",
       " 'ħЩƷתƵԶĵط',\n",
       " '110',\n",
       " '',\n",
       " 'Ҫѧϰ',\n",
       " 'ܸ',\n",
       " 'ù˵лл',\n",
       " 'лл',\n",
       " 'ܿģҲûһЩķ',\n",
       " '۵',\n",
       " '˿',\n",
       " 'ճ',\n",
       " 'ʵԼԸ',\n",
       " 'ȥһEd Sheeranݳ',\n",
       " 'κ',\n",
       " '',\n",
       " 'Ҳʱɣÿ˶ѡ\\U00076f38ñ',\n",
       " 'һ㶼ںͬѧļҳȥʲôȥʲô',\n",
       " 'ʲôʲô',\n",
       " 'κιĵ飬ͨŻNBA',\n",
       " 'һǸ˿ʼ֤',\n",
       " '˶ ʱ ѧϰ',\n",
       " 'һȥȫ',\n",
       " 'ڴ',\n",
       " 'һͬ',\n",
       " 'ͺ',\n",
       " 'ѧϰ',\n",
       " 'ȥ',\n",
       " '',\n",
       " 'ѧϰ\\ue8ec֣ţ磬ѧУ',\n",
       " '',\n",
       " 'ֵ',\n",
       " '',\n",
       " 'ӹ thank you',\n",
       " 'лл',\n",
       " '',\n",
       " 'Ҹһ˳',\n",
       " 'ʮѤ',\n",
       " '',\n",
       " '',\n",
       " 'cСⷰһ',\n",
       " 'ð',\n",
       " '',\n",
       " '̻濴ǴӲ濴',\n",
       " 'й',\n",
       " 'Ϻ֧Ԯ',\n",
       " 'ҾҪһЩҵȤ',\n",
       " 'лл',\n",
       " 'ʹಢ',\n",
       " '',\n",
       " 'ʱӦ',\n",
       " 'depends onҵʱ',\n",
       " '',\n",
       " 'ӰӾ硢С˵Ρý',\n",
       " '',\n",
       " 'ҵУParty',\n",
       " 'Ь· ĸ ճ',\n",
       " 'ȫ',\n",
       " '',\n",
       " 'ȥȥĵط',\n",
       " '',\n",
       " 'insϵŮ',\n",
       " 'Ϊ',\n",
       " 'Ҹưɣһ̸',\n",
       " '彡',\n",
       " 'ɶ',\n",
       " 'ְԣ\\u05f7ճ',\n",
       " 'Ūһп',\n",
       " '˼壬δܻᱬľΣԼ۵',\n",
       " 'зĿɳ',\n",
       " 'һ',\n",
       " 'ü˺Լһƽ',\n",
       " 'ϷѧϰͳԵ',\n",
       " 'һ˵Ʊ',\n",
       " 'ߵ',\n",
       " 'Ư',\n",
       " 'Ҷ༸һУͳͳʯ',\n",
       " 'лл',\n",
       " 'Ҿ˵лл',\n",
       " 'ʼգ',\n",
       " 'ÿ',\n",
       " 'л',\n",
       " 'Ȱ˵סļ',\n",
       " 'Ѱұ˵İ',\n",
       " 'ͬѧæ',\n",
       " '˵Цߣһͺͷ',\n",
       " 'òʾл',\n",
       " '',\n",
       " 'Ҫ\\u0530˭',\n",
       " 'ĳ˵ ϾοԤ',\n",
       " '',\n",
       " 'Բ',\n",
       " 'һһԵ˵Ǧ',\n",
       " 'ɶ',\n",
       " '',\n",
       " 'ΪʲôҪȵ',\n",
       " 'LOL',\n",
       " 'Ҫ˭죬ͨΪճѧϰ',\n",
       " 'Ůһ',\n",
       " '',\n",
       " 'һԵ',\n",
       " 'ƿ',\n",
       " 'hi',\n",
       " 'ͲͨĬ',\n",
       " 'ҿԸĵԼĻϰߣӵһЩϰ',\n",
       " 'õһ',\n",
       " 'ѿ û\\u07b8',\n",
       " 'һ˵Ʊ',\n",
       " 'ȥܳϿҵ',\n",
       " '',\n",
       " 'ֺ֧ͷ',\n",
       " 'ڳվ',\n",
       " 'һǸ',\n",
       " 'ḻ˸еҸ',\n",
       " 'ƽƽ',\n",
       " '\\u07b8',\n",
       " 'ٿ',\n",
       " 'л֮',\n",
       " 'һܲˬǸƵˣͬʱΪе̾Ϣ',\n",
       " 'İ',\n",
       " 'ҵϽиõĲ',\n",
       " 'һ㲻',\n",
       " 'Լศɵ',\n",
       " '\\u07b3',\n",
       " 'ҾҵӦñʱɣҵ˵Ļҿܻ',\n",
       " 'Ŀ֣Ȼзǻַָ̽ȡ',\n",
       " '',\n",
       " 'һʲôԸĵ',\n",
       " 'СС',\n",
       " '˵ллȻӹǦ',\n",
       " 'ضһ飬ҪʲôĽ',\n",
       " 'ҵһ',\n",
       " 'ҾһǿԴ\\u07bfܵġ',\n",
       " 'Ϊʲôô',\n",
       " 'ܳϿҵƱϵ',\n",
       " '֧',\n",
       " 'ϿҵǸ˵Ʊ',\n",
       " '˾',\n",
       " 'ŰƷһ飬趨ɿռĵط\\u07b8',\n",
       " '',\n",
       " 'Լ',\n",
       " 'ٿ˾',\n",
       " '̸',\n",
       " 'ֱ',\n",
       " 'ȻϿҵ˵Ʊ',\n",
       " 'һϸ\\u07b8С˵Ŭ',\n",
       " 'Ȥ',\n",
       " 'Ǹô',\n",
       " '˵лл',\n",
       " 'һֱ\\u07b8',\n",
       " 'ѡϿҵ',\n",
       " 'л',\n",
       " 'ѿѰ',\n",
       " 'ֵȵȣ˰Ķ',\n",
       " 'ܺ˵',\n",
       " 'ҾÿܻΪ̫нԣ˼ԡҶҵ',\n",
       " 'ǿ϶ҵ',\n",
       " '\\u07b3',\n",
       " '\\u07b8ĸ',\n",
       " 'лл',\n",
       " 'ٿ',\n",
       " '\\u07b8',\n",
       " 'Ȼ',\n",
       " 'лº',\n",
       " '',\n",
       " '',\n",
       " 'Ȼ',\n",
       " 'ǻ',\n",
       " 'У칫Ҹлصİɰι',\n",
       " '˵',\n",
       " 'Ͽҵ',\n",
       " 'һ˵',\n",
       " '',\n",
       " 'УԴ֣Ķһֲ',\n",
       " 'ѡӳϿҵƱ',\n",
       " 'Ͽҵ˵',\n",
       " 'һ춯ص飬ع㣬\\u07ba',\n",
       " '',\n",
       " 'лл',\n",
       " 'һٶһ飬ٽǷҪ\\u07b8',\n",
       " 'ٿû\\u07b8ĵ',\n",
       " 'лл',\n",
       " '˵лл',\n",
       " '뷨д Ҫ\\u07b8ĵøӿʵ',\n",
       " 'ᱻͬ',\n",
       " '\\u07ff\\u07b8',\n",
       " 'һԼƷ©',\n",
       " 'Ի\\u07b3',\n",
       " 'ϣҵյƫĶԴҵþͿþʵУѡܡ',\n",
       " 'ӹ',\n",
       " 'İ',\n",
       " 'лta',\n",
       " 'ѡϵ',\n",
       " '¿ ҳû',\n",
       " 'ǷḻȤ ˳澳',\n",
       " 'õ',\n",
       " 'ǰǸ˵Ʊ',\n",
       " '\\u07b8',\n",
       " 'ҳϿҵ',\n",
       " 'һȥһ˵Ʊ',\n",
       " '',\n",
       " 'һ˵Ʊ',\n",
       " '',\n",
       " 'ϣҵΧ֮ھƷͬʱҵҵĻ',\n",
       " 'һѡ۳ƱΪϴҶƵ˶ӽ',\n",
       " 'Ŭܶһ',\n",
       " 'Ͽĸ',\n",
       " 'ҵ',\n",
       " 'interest',\n",
       " '',\n",
       " 'лӹǦ',\n",
       " 'оûط\\u07b8',\n",
       " 'Ͻ',\n",
       " 'лл',\n",
       " 'һûʲôҪĵ',\n",
       " 'ͬͬ',\n",
       " 'ԵҪ\\u07b8',\n",
       " 'emmmͬҲзԵİ',\n",
       " 'ҵϽиõĲ',\n",
       " 'ȥθˣ\\u07b8',\n",
       " 'һú\\u07b8',\n",
       " 'лл ô֪',\n",
       " 'лл',\n",
       " '\\ufde8\\U000e3b38Mr.ChromeckiĿҪһ',\n",
       " 'Լѡ',\n",
       " 'ҵһ',\n",
       " 'Ҹ',\n",
       " '˵Ʊ',\n",
       " 'ȫƽo',\n",
       " 'ƽ͵̸УúѺõ̬˵',\n",
       " 'Ʊ',\n",
       " '',\n",
       " 'ٿһ飬\\u07b8һ',\n",
       " 'ʱʱʹûڵ',\n",
       " 'Լ',\n",
       " '',\n",
       " 'ѡϿҵ',\n",
       " 'ҵİɣ˵',\n",
       " 'Ʊ',\n",
       " 'Ͽҵ˵ƱС',\n",
       " 'һĺԲҲ',\n",
       " 'ɣȻ˵Լ',\n",
       " 'һῪʼargue',\n",
       " '˵Ȼ\\u07b8',\n",
       " 'һһĿǷҪ\\u07b8',\n",
       " '˵лл',\n",
       " 'лл',\n",
       " 'ټһ',\n",
       " 'Ƿ',\n",
       " 'ڼһûʲôҪĵĵط',\n",
       " '',\n",
       " 'µõͬ˹෴ʱõ',\n",
       " 'һԣԼᱻϿɣǺѧԼѧϰصĿ',\n",
       " 'һʱŲ\\u07b8ģΪһߣϣ\\u07b5ʱڿԾơ',\n",
       " 'ñ˸',\n",
       " 'ǻ϶ҵ',\n",
       " 'лллл',\n",
       " 'Ķ ҪĽĵطԼ˼ ٽһ\\u07b8',\n",
       " 'ٿһ\\u9ff4ʲôԵ',\n",
       " 'лл',\n",
       " 'ѵʿο',\n",
       " '',\n",
       " '',\n",
       " 'ƽ\\U0003acf5',\n",
       " 'first one',\n",
       " '\\uecbb',\n",
       " 'ѡϿҵ',\n",
       " '\\U000b0861',\n",
       " 'Լ',\n",
       " 'Ĺ',\n",
       " 'һ',\n",
       " 'һа',\n",
       " 'ȥƱ',\n",
       " 'ƽ',\n",
       " '',\n",
       " 'ȥ',\n",
       " 'Բ',\n",
       " 'ѡ̬Ⱥõ',\n",
       " '',\n",
       " 'Ƶ',\n",
       " '',\n",
       " 'ȡĿԼĿ',\n",
       " 'лл',\n",
       " 'ʱٶһΣһ\\u07b8',\n",
       " 'ллĸ̾ϸ',\n",
       " 'Ϊʲô',\n",
       " 'ضС˵',\n",
       " '鷭Ƿд\\U000e3b38˿ñ',\n",
       " 'ȶ',\n",
       " 'һڿһϸ',\n",
       " 'ĵó䲻',\n",
       " 'Ի϶',\n",
       " 'ʱд',\n",
       " 'лл',\n",
       " '\\u03a2ĸ',\n",
       " '\\U000feae3˾֮Ҳ',\n",
       " '˵ۣôõ\\uf8e1лл',\n",
       " '˵лл',\n",
       " 'ԷԼ',\n",
       " 'ҵķ',\n",
       " 'ͬ',\n",
       " '˵',\n",
       " 'һҵһƱ',\n",
       " 'һΪΰȫ֪ȫȫܵεһǰɶƷֳ',\n",
       " 'ȥƽʵ׳',\n",
       " '˼һ',\n",
       " 'һǸϿҵ',\n",
       " 'Ӧ',\n",
       " '̬Ⱥõ',\n",
       " 'ϵŮӵĿںζĽ',\n",
       " 'ӵ',\n",
       " 'ļ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '϶Ҷвͬ뷨Ѷ϶',\n",
       " 'ۺƯ',\n",
       " '۽УǽܽΪ£ʵϣ',\n",
       " '˼ײ',\n",
       " 'лл',\n",
       " 'һ',\n",
       " '\\u07b8',\n",
       " '˵лл',\n",
       " 'ܣлл¿ٸ˵ϸ',\n",
       " 'ԃҊK\\u07b8',\n",
       " 'ܻᱻ',\n",
       " 'ύ',\n",
       " 'ѿ˵дcomment',\n",
       " 'ܺ',\n",
       " 'ϸĶ',\n",
       " 'лл',\n",
       " 'ڼʹ\\u07b8',\n",
       " '˵лл',\n",
       " '˵ллл',\n",
       " '\\u07b8',\n",
       " 'һEvidencelines of reasoning 粵ƿ',\n",
       " 'ƯɡҲ',\n",
       " 'ۣ˵',\n",
       " '\\u07b3ɣٷ',\n",
       " 'Ȼǵһ˰',\n",
       " 'һ˵',\n",
       " 'ǸϿҵ˵Ʊ',\n",
       " 'õĵ',\n",
       " 'Լ',\n",
       " 'Ȼ˵Ʊ',\n",
       " 'ս',\n",
       " '',\n",
       " 'õһ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'һܿģȻ´αΪпΪͻͶ߶ʧȥ',\n",
       " '˶Լ棬˼άȹȵһЩ̽',\n",
       " 'ѡ',\n",
       " 'Ǹ',\n",
       " 'let her go',\n",
       " 'Լ벻ܶԱ˷Ƣ',\n",
       " 'м/ѯô֪군˵',\n",
       " 'һ',\n",
       " 'ĶȫĲûгĲ',\n",
       " '˵:\"лл\"ʮָж',\n",
       " 'ټһ',\n",
       " 'άģĶƴ',\n",
       " 'ọ̈̄',\n",
       " 'Щ\\u07b3ɣЩ',\n",
       " 'õ',\n",
       " 'ڲͬ',\n",
       " 'hh',\n",
       " 'ٿѯ',\n",
       " '',\n",
       " '\\u07b8ֱdeadline',\n",
       " 'ٿһ',\n",
       " 'ллthanks',\n",
       " 'л',\n",
       " 'ٿһ',\n",
       " 'ز˵뷨ٴ˼ԼĿ',\n",
       " 'ӺͶͬ\\u0530ߣǴҲعֿҲ',\n",
       " '',\n",
       " 'ѡϿҵ',\n",
       " 'Ҷţƣ',\n",
       " 'ѡһ',\n",
       " 'ͱһѾ\\u07b9ִ',\n",
       " 'ҵ',\n",
       " 'Ͽҵĵһ',\n",
       " '',\n",
       " 'ͨ',\n",
       " 'ȥһ',\n",
       " '',\n",
       " 'ûʲô˵ģ˹۵',\n",
       " 'Է',\n",
       " 'ΪΪ',\n",
       " 'Ȥ',\n",
       " '',\n",
       " 'һenjoy',\n",
       " '',\n",
       " 'ѧϰ',\n",
       " 'ӺͶͬ',\n",
       " 'ѡϿҵ',\n",
       " 'ճ\\ue8ecͬȤãѧϰ',\n",
       " '֣ճ',\n",
       " 'л',\n",
       " 'зḻľҲƽ',\n",
       " '',\n",
       " 'άǸ۵ıȽϺÿ',\n",
       " 'ŮӦ',\n",
       " 'лл',\n",
       " 'Ư',\n",
       " 'һᱻ',\n",
       " '',\n",
       " 'лл',\n",
       " 'һ͵͵İҪִĵ͵͵ĴߣȻϽϵ˲\\u0863',\n",
       " 'л',\n",
       " 'úÿ',\n",
       " 'Լо\\u07b4ħֻʱ\\U000b1b37ܾ\\u07b9֣ԥԼЩ',\n",
       " 'ȥ',\n",
       " 'л',\n",
       " '˵лл',\n",
       " '',\n",
       " 'ӹ',\n",
       " 'е',\n",
       " 'ճ',\n",
       " 'ֺ\\ue8ecϷ',\n",
       " 'Ŀ Kfҵ뷨',\n",
       " 'һ˵',\n",
       " 'ѡ̬Ⱥõ',\n",
       " 'ճ',\n",
       " 'ϣУ¼',\n",
       " 'ճ飬',\n",
       " 'ۿ',\n",
       " 'һѡٷԼ',\n",
       " 'ƽ c',\n",
       " 'һ',\n",
       " 'ԼҲΪѱ',\n",
       " '',\n",
       " 'ѧ',\n",
       " 'һֻŮƱ',\n",
       " '',\n",
       " '',\n",
       " 'ͬѧǳȥK/ȥֳ/ȥɽ¶Ӫ',\n",
       " 'ճ',\n",
       " '\\ue86bȤ',\n",
       " 'ճ\\ue8ec',\n",
       " 'һ˵Ʊ',\n",
       " 'Ǹ˵ҲҪԼ',\n",
       " 'ְԣ',\n",
       " '̫ÿ˰',\n",
       " 'ѧϰ',\n",
       " 'ѧϰճ',\n",
       " 'ܺ/һͺ',\n",
       " 'Ȼܲ˵лл',\n",
       " 'ܺϲһ',\n",
       " 'ˬ',\n",
       " 'ӹ ˵лл',\n",
       " 'ҿܻĳһֶþ\\u07b9ע⣬ȥǼҪպãһԴӻִУ칫ҵɭ·Ѿ\\u07b9ɭ֣ɭֵĵͣ֩루ڶϢأ÷ʳ֩\\u07b9',\n",
       " 'лл',\n",
       " 'λӰ',\n",
       " 'ƷõĲ\\uecbbĶĴǸĴڵ',\n",
       " 'ˬ˷',\n",
       " 'ҹ',\n",
       " 'ˬ',\n",
       " '˵лл',\n",
       " '˭',\n",
       " '',\n",
       " 'cool',\n",
       " 'xx',\n",
       " '²˵лл',\n",
       " '',\n",
       " 'Ҹ',\n",
       " 'ͨں',\n",
       " 'ѧУ',\n",
       " 'Լ',\n",
       " 'ÿ',\n",
       " '',\n",
       " 'ĽǶȿ',\n",
       " 'ճ',\n",
       " 'ҾѧһЩݣ\\uf8ecиԼֹʿγ̿Եȡ',\n",
       " 'ͬ Ļʷ ˼ʹϵ',\n",
       " 'úõرԼĿ',\n",
       " '㸸ĸһ',\n",
       " 'ȥȥĵط',\n",
       " 'ѯ',\n",
       " 'Ϸ',\n",
       " 'Ҳϲ˷ʱڱ',\n",
       " '̸߹ϣԷǸ',\n",
       " 'ûرûյĵ',\n",
       " 'argueһ',\n",
       " 'ѧϰһЩݻһЩԼ˵£ǹһЩʱ£BվĶ߹\\U000e3b3700ȽϸȤһЩ±ȽеĻ',\n",
       " 'ֵӰ',\n",
       " 'ճͶ',\n",
       " '˵Լ뷨',\n",
       " 'Ʊһ',\n",
       " '',\n",
       " '˵ͳһս',\n",
       " 'ҵ \\uefad',\n",
       " '',\n",
       " '',\n",
       " 'ƯQAQ',\n",
       " '˵ллãһΰ',\n",
       " 'ллȻ',\n",
       " 'ٿ\\u07b8',\n",
       " '',\n",
       " 'Ҫɲ۵С',\n",
       " 'лл',\n",
       " 'ȥ۳ǳԷ',\n",
       " 'ߴ',\n",
       " 'Ǽħߵ',\n",
       " 'ΥҲˮ˳Ȼӡ',\n",
       " 'շ',\n",
       " 'ħתƷ',\n",
       " '',\n",
       " 'ӹ˵лл',\n",
       " 'Ư',\n",
       " 'Ƥ',\n",
       " '˿æṩ\\u07b8',\n",
       " '˶࣬Ǻܺÿ',\n",
       " 'лл',\n",
       " 'ճ',\n",
       " 'ѧϰ',\n",
       " 'ճ',\n",
       " '',\n",
       " '',\n",
       " 'һ˽Ϊʲô˵ʲôȻٶԱҵɣҾǶԵģôһ᳢ȥ˵',\n",
       " 'ɽ',\n",
       " '',\n",
       " 'ѧУ',\n",
       " 'ѧϰ',\n",
       " 'ȥ',\n",
       " 'ȷĿ',\n",
       " 'Լ뷨',\n",
       " 'ҪǮĻ齨һ̨һĵ(һһС壬˫·e52080ȾСﵱnas)',\n",
       " '֤ԼĹ۵㣬Ŭ˵',\n",
       " 'һȥɡ',\n",
       " '',\n",
       " 'ÿ˵Ƿ˿',\n",
       " 'ҵ',\n",
       " 'ϷϢһЩʮֱҪĶ',\n",
       " 'ճ',\n",
       " 'ú˵ΪʲôҲͬ',\n",
       " 'Ҿ̻ȽʺϾգǳʺΡ',\n",
       " 'һһѺһȥ',\n",
       " 'һargue',\n",
       " 'Ů',\n",
       " 'ճѧרҵ',\n",
       " '',\n",
       " 'ٿ ȵʱٽ',\n",
       " 'ӹл',\n",
       " 'лл',\n",
       " 'ܮ',\n",
       " '',\n",
       " 'һԭУҧɽɡǧز\\u0862պ\\u0863',\n",
       " 'ֱһDr.Strange ʱ䱦ʯ\\u07b8ȻѾ\\u07b9СȻ\\u0378\\uf8ecȻݺ',\n",
       " 'Ҹ',\n",
       " 'һ˵ллд¿λ',\n",
       " 'Dumbledoreٻ',\n",
       " '²л',\n",
       " 'ٻħϵͳİУ;\\u07b9ֶƯӣȻ\"Ϊһ\"ЩǺǻҿŮվݴϷҪ',\n",
       " 'аæ',\n",
       " 'ˬ',\n",
       " 'Ȼ˵лл',\n",
       " '',\n",
       " '˵лл',\n",
       " '',\n",
       " '\\u07b8',\n",
       " 'ллУӹ',\n",
       " 'Фճ',\n",
       " 'ճ밮',\n",
       " '',\n",
       " 'I\\\\˵Ʊ',\n",
       " '',\n",
       " '뷨˵ȡ',\n",
       " 'ܺÿ',\n",
       " '\\ue8ecѧϰ',\n",
       " 'ƽ',\n",
       " 'ʵҪAPһ',\n",
       " 'ҰŮƱ',\n",
       " 'ͨɻ֧ҵĹ۵㣬ʾ뷨',\n",
       " 'Դ˲Ӧ Ҳ˵Լʵ  Ͼ˿ܷ',\n",
       " 'ȥ',\n",
       " 'ллȻ',\n",
       " 'ļȥ',\n",
       " 'Ϊʲôвͨ',\n",
       " '',\n",
       " '˯',\n",
       " 'ĬĬ\\u07ff',\n",
       " '',\n",
       " '˵',\n",
       " 'Ա뷨ϴ\\U000f1ef7',\n",
       " '',\n",
       " 'ʵҾǶԵ',\n",
       " 'ҵ',\n",
       " 'ѧ',\n",
       " '\\u2d7dɣУ',\n",
       " '۲Ǹˣû',\n",
       " 'ε£㻹',\n",
       " 'ѯһ',\n",
       " 'һЩ֣ΪҵûǦʺУҿƲһעһʱ䣬ƶϳûдʺе',\n",
       " '¶',\n",
       " '\\ue8ecû',\n",
       " 'Լƿ',\n",
       " 'ʲô',\n",
       " '',\n",
       " '',\n",
       " 'õ',\n",
       " 'ͦõ  Ҳܶ   ѡھסĵط',\n",
       " '',\n",
       " '±ȴֻԶԣ۵㱻',\n",
       " 'ʲô',\n",
       " 'ʲôҲȵ',\n",
       " '˯һ',\n",
       " 'ѧϰ',\n",
       " '֪Ǹ˰',\n",
       " 'ûû',\n",
       " '¶',\n",
       " 'ٿ',\n",
       " 'ε\\u03a2Цͷлл',\n",
       " 'ܻᱻܾܻᱻ',\n",
       " 'ô',\n",
       " 'һֱӰ֪ʶ͵ԺеĻ',\n",
       " '֮գһߣ֮Сˡºʿ䣬δڶ',\n",
       " 'У鷳\\u0863',\n",
       " '',\n",
       " 'οչ',\n",
       " '˵ɺҪ',\n",
       " 'ѧϰ',\n",
       " '\\u05fcգ',\n",
       " 'ѡһ',\n",
       " '',\n",
       " 'ѧϰ',\n",
       " 'һᱩǸƵһȻƱ',\n",
       " 'į',\n",
       " 'ллӹǦ֮TAΪ',\n",
       " 'ԭ۹',\n",
       " '',\n",
       " '֪һ',\n",
       " 'ͨںͬѧķ',\n",
       " 'κǾ˯һ',\n",
       " 'Сѡз',\n",
       " '뷨һ',\n",
       " 'ԵķԵ',\n",
       " '(û⣩',\n",
       " '',\n",
       " '෴',\n",
       " 'sat1600и120gpa5.0õУoffer',\n",
       " 'ѧħ',\n",
       " '',\n",
       " 'ܾ',\n",
       " 'תͷԷ',\n",
       " 'ŮеĻ첻ҪϤĻ߸л',\n",
       " '',\n",
       " 'ȥѧϰ',\n",
       " 'ûȥ',\n",
       " 'Ͷ˵',\n",
       " 'һ',\n",
       " 'ͻ',\n",
       " '̫',\n",
       " 'һİ˵Ĺ',\n",
       " 'ע',\n",
       " 'תƾ\\u07b9ע',\n",
       " 'һɵ',\n",
       " '',\n",
       " 'ûйյϰ',\n",
       " '¹ȥ',\n",
       " 'bb',\n",
       " '',\n",
       " 'ߴ',\n",
       " 'ܲᱻɣԱ',\n",
       " '',\n",
       " 'ѧͽ',\n",
       " '취ŪȻ',\n",
       " 'ȻǻǺݳһ',\n",
       " 'úϢ',\n",
       " '',\n",
       " 'Ͻ',\n",
       " '\\u07b8',\n",
       " '\\u07b8',\n",
       " 'ζ飬ػ־µµΪ',\n",
       " 'ûĶתע',\n",
       " 'ҿ\\u0378˵һкܶìܵĵط',\n",
       " 'ûĿ',\n",
       " '',\n",
       " 'թװȻ͵͵',\n",
       " '',\n",
       " 'ħȥ',\n",
       " 'ƭҪԼ',\n",
       " 'ζȤ',\n",
       " 'Ǹ\\u07b9ֵעˤ',\n",
       " 'ҵģ',\n",
       " 'һ\\u1cbbڱ\\U000f997b',\n",
       " 'ø',\n",
       " 'Ŷ·ӣȻ',\n",
       " 'һصĲ',\n",
       " '',\n",
       " 'Сģ˾ڹڲ̫ģ',\n",
       " '',\n",
       " 'յģƬڿռ',\n",
       " '',\n",
       " '\\u07b8',\n",
       " 'һŬԿ\\u07b9֣',\n",
       " 'ٵ',\n",
       " '',\n",
       " '㿴',\n",
       " 'ν',\n",
       " 'µµΪе㶫',\n",
       " 'ע  ͵Ϯ',\n",
       " '˺',\n",
       " 'Сִ',\n",
       " 'Ȼᱻ',\n",
       " 'תע',\n",
       " '\\u03a2˹ˣ˭飬',\n",
       " '',\n",
       " '',\n",
       " '뿪',\n",
       " '±',\n",
       " 'Ǵ',\n",
       " 'Ҳ',\n",
       " 'Ҫ\\u07b8Ļȡ',\n",
       " '',\n",
       " '',\n",
       " 'лЦб',\n",
       " 'Ķģһ\\u05f7ȴöյĹ',\n",
       " 'Ӧòô죬ܻƲһ',\n",
       " '\\u07b8',\n",
       " 'ȥ棡',\n",
       " 'ҾһûκģȽ˼',\n",
       " 'Ҿ̻ģˣͲ뿴ڶ',\n",
       " 'ԥύ',\n",
       " '\\u07b8',\n",
       " 'ҵ',\n",
       " 'ԼӰ',\n",
       " 'ì',\n",
       " 'ܻ\\U000b7d32',\n",
       " 'Լ',\n",
       " 'Ȱ˵',\n",
       " 'ȥ',\n",
       " '',\n",
       " 'סĴ',\n",
       " 'Լһѹ',\n",
       " 'ѹ',\n",
       " 'ɱУ',\n",
       " 'ҲμۣǸԱҪҪ뿪¡Ҵûϲֶӡ',\n",
       " '',\n",
       " 'ʲôⰡ...',\n",
       " 'Լ෴',\n",
       " 'ܹ¶',\n",
       " 'ź',\n",
       " '\\u07b8',\n",
       " '',\n",
       " 'ʱ̻',\n",
       " '¶',\n",
       " 'ݽ',\n",
       " 'ܹµ',\n",
       " 'ҺòңΪʲôؼҳԷ',\n",
       " '',\n",
       " '',\n",
       " '뿪',\n",
       " 'Ϊ',\n",
       " 'ܵ',\n",
       " 'һ',\n",
       " 'ĵطȥ',\n",
       " '֪',\n",
       " '˵ΪʲôĻֱӸ',\n",
       " 'ӡ',\n",
       " '̸',\n",
       " '',\n",
       " '֪',\n",
       " '̸',\n",
       " 'ʼͷ',\n",
       " '뷨ǿԺ\\U000f2efbڸ˿Ⱥ̫\\U000fb976',\n",
       " 'ҵг˫գ겻ô',\n",
       " 'һߣԼȥ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '˾',\n",
       " 'һ\\u07b8ģȻſԼ',\n",
       " '',\n",
       " '',\n",
       " '涼й',\n",
       " 'ʵΪ˿ʲô֧',\n",
       " '',\n",
       " 'ҵǰ',\n",
       " '',\n",
       " 'Ա',\n",
       " 'Ի',\n",
       " '£Щ̬̫õ˷й',\n",
       " '˯һ',\n",
       " 'Ǯ',\n",
       " 'ǸƵģΪһпǼƱ',\n",
       " '̫',\n",
       " 'û',\n",
       " 'һ',\n",
       " 'ǰ',\n",
       " '.....ӦñҺ......',\n",
       " 'û',\n",
       " 'ʱ',\n",
       " '\\u07b3',\n",
       " 'ҵ',\n",
       " 'ȥ',\n",
       " 'ŪһݱϹ',\n",
       " 'ҲҵһҲˣʵȡÿεʲôѽ',\n",
       " '˺ö',\n",
       " '̫',\n",
       " 'ʹ',\n",
       " '˵',\n",
       " '',\n",
       " 'ŻһЩֵֹ⣿ô֪',\n",
       " 'ȥס',\n",
       " 'ѧϰ',\n",
       " 'һٿĹ˾',\n",
       " 'լڼ',\n",
       " '˼˵',\n",
       " 'ҿ϶һò˵ллòˬǸеƵˡ',\n",
       " 'ƴ',\n",
       " '',\n",
       " 'ͻ',\n",
       " 'ʹƽ',\n",
       " '',\n",
       " 'ǰ',\n",
       " '̫',\n",
       " 'ö',\n",
       " 'ٵ',\n",
       " '\\u07b8ˣ罻',\n",
       " 'ٵ',\n",
       " 'һῴž\\u07b9ְƻ\\u03a2Ц뿪',\n",
       " '\\u07b8',\n",
       " 'ù¶',\n",
       " 'Ǹ۴⣨',\n",
       " '翵',\n",
       " 'ؼ',\n",
       " '뿪ξ',\n",
       " 'ҵ',\n",
       " 'תע֮ģ',\n",
       " '췢',\n",
       " 'һʧȥ',\n",
       " 'ƱطƱ',\n",
       " 'Ӵ֮ûƱ',\n",
       " 'ǱҪ',\n",
       " 'ɱ',\n",
       " '˽',\n",
       " '',\n",
       " '',\n",
       " 'иĿҲǿȱ뷨һ£˳Ȼ',\n",
       " 'Һε',\n",
       " 'ӦȥԼ',\n",
       " '¶',\n",
       " 'һֱϽҵƷ',\n",
       " 'Ʒ',\n",
       " 'ٵ',\n",
       " '',\n",
       " 'ȸлѽ',\n",
       " '飬˯',\n",
       " 'һھƵ\\uf863Ҳϲš',\n",
       " '',\n",
       " 'ģֻµʱ',\n",
       " '봽Ϸ',\n",
       " 'Ե',\n",
       " 'ͬҲбʵķԹ۵',\n",
       " 'ͦġҪ\\u0378',\n",
       " 'ҾðӦ',\n",
       " '',\n",
       " 'ǺܶĿ..',\n",
       " 'ƽĹȥ',\n",
       " 'ЩĵĻʱ',\n",
       " 'Ⱥ',\n",
       " 'ΪʲôҪ',\n",
       " 'һһ',\n",
       " 'νܲ˵лл',\n",
       " 'ö˰',\n",
       " 'ǲǴδ',\n",
       " '¶',\n",
       " 'һڶ˵Ʊ',\n",
       " 'ҵ',\n",
       " 'ӸľګС˹֮֮Ť̬ͨл֮˷СҮ֮̾ܿܿʶҲ',\n",
       " 'и110',\n",
       " 'ɫ',\n",
       " 'ȥƺϷдƪͷͷǵĳԼÿıƺش',\n",
       " '',\n",
       " 'ÿ ׳....',\n",
       " 'ѯƱοѡ',\n",
       " '\\U00076a3bԼ˲õĻ䣬iǱҵĻ֮ҵּӴ',\n",
       " '뿪ǸѡȨ档زͬ۵㡣',\n",
       " 'ĩҵļԼѷ',\n",
       " 'ԶУû֪ұ',\n",
       " 'Ҳ',\n",
       " '֪',\n",
       " 'һͷߵγлл',\n",
       " '̻𡣾',\n",
       " 'Ϊʲô',\n",
       " 'ҪƤˮʣͻˮʣɫۣȻ˵лл',\n",
       " 'һؾܾԱ˵Ǧ',\n",
       " 'typical',\n",
       " 'û',\n",
       " 'ϣҵտ\\u0530ʵʵֵĶ',\n",
       " 'ѧɳ',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'Ҳ֪',\n",
       " 'ִÿвͬĿ',\n",
       " '\\u07b7ί߶ѣпġǧԽգ棡죬棬\\u0cbb֮Ҳ',\n",
       " 'ѧ',\n",
       " 'ֻ',\n",
       " 'ž·жǡ',\n",
       " '',\n",
       " '£˵лѯԭ',\n",
       " 'ΪʲôҪ̻ڼ˯',\n",
       " '̻貵ֻһ˲',\n",
       " 'ɶɶ',\n",
       " '',\n",
       " '˯',\n",
       " '',\n",
       " 'ÿвͬ뷨 ҲЩֻ벩ùע  Լϲͺ',\n",
       " 'cԼҊȫ෴Ҋ',\n",
       " '֪',\n",
       " 'ǵжŻϦҹһ˿̻',\n",
       " 'ܶ',\n",
       " '棡ķмлʤҩʵ֮٣֪䲻Ӱ֮Ү֮\\uf8ecܲкຮʮأʫвأȿ۸ϲ֮',\n",
       " 'кʵʣ쿪',\n",
       " 'ʲô˵ ÿ뷨ͬ\\uf87f',\n",
       " '',\n",
       " 'صȥ',\n",
       " '˵',\n",
       " '',\n",
       " 'ܹ¶',\n",
       " 'ϼ']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "989"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_texts_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们使用tensorflow的keras接口来建模\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding, LSTM, Bidirectional\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**分词和tokenize**  \n",
    "首先我们去掉每个样本的标点符号，然后用jieba分词，jieba分词返回一个生成器，没法直接进行tokenize，所以我们将分词结果转换成一个list，并将它索引化，这样每一例评价的文本变成一段索引数字，对应着预训练词向量模型中的词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\EdiC\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.994 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# 进行分词和tokenize\n",
    "# train_tokens是一个长长的list，其中含有4000个小list，对应每一条评价\n",
    "train_tokens = []\n",
    "for text in train_texts_orig:\n",
    "    # 去掉标点\n",
    "    text = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\",text)\n",
    "    # 结巴分词\n",
    "    cut = jieba.cut(text)\n",
    "    # 结巴分词的输出结果为一个生成器\n",
    "    # 把生成器转换为list\n",
    "    cut_list = [ i for i in cut ]\n",
    "    for i, word in enumerate(cut_list):\n",
    "        try:\n",
    "            # 将词转换为索引index\n",
    "            cut_list[i] = cn_model.vocab[word].index\n",
    "        except KeyError:\n",
    "            # 如果词不在字典中，则输出0\n",
    "            cut_list[i] = 0\n",
    "    train_tokens.append(cut_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**索引长度标准化**  \n",
    "因为每段评语的长度是不一样的，我们如果单纯取最长的一个评语，并把其他评填充成同样的长度，这样十分浪费计算资源，所以我们取一个折衷的长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得所有tokens的长度\n",
    "num_tokens = [len(tokens) for tokens in train_tokens]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.950455005055612"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 平均tokens的长度\n",
    "np.mean(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最长的评价tokens的长度\n",
    "np.max(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log(num_tokens), bins = 100)\n",
    "plt.xlim((0,5))\n",
    "plt.ylabel('number of tokens')\n",
    "plt.xlabel('length of tokens')\n",
    "plt.title('Distribution of tokens length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取tokens平均值并加上两个tokens的标准差，\n",
    "# 假设tokens长度的分布为正态分布，则max_tokens这个值可以涵盖95%左右的样本\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9534883720930233"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取tokens的长度为236时，大约95%的样本被涵盖\n",
    "# 我们对长度不足的进行padding，超长的进行修剪\n",
    "np.sum( num_tokens < max_tokens ) / len(num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**反向tokenize**  \n",
    "我们定义一个function，用来把索引转换成可阅读的文本，这对于debug很重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用来将tokens转换为文本\n",
    "def reverse_tokens(tokens):\n",
    "    text = ''\n",
    "    for i in tokens:\n",
    "        if i != 0:\n",
    "            text = text + cn_model.index2word[i]\n",
    "        else:\n",
    "            text = text + ' '\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse = reverse_tokens(train_tokens[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下可见，训练样本的极性并不是那么精准，比如说下面的样本，对早餐并不满意，但被定义为正面评价，这会迷惑我们的模型，不过我们暂时不对训练样本进行任何修改。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'干了一番惊天动地的事情但最后回归宁静满足死而无憾'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 经过tokenize再恢复成文本\n",
    "# 可见标点符号都没有了\n",
    "reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'干了一番惊天动地的事情，但最后回归宁静，满足，死而无憾'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 原始文本\n",
    "train_texts_orig[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**准备Embedding Matrix**  \n",
    "现在我们来为模型准备embedding matrix（词向量矩阵），根据keras的要求，我们需要准备一个维度为$(numwords, embeddingdim)$的矩阵，num words代表我们使用的词汇的数量，emdedding dimension在我们现在使用的预训练词向量模型中是300，每一个词汇都用一个长度为300的向量表示。  \n",
    "注意我们只选择使用前50k个使用频率最高的词，在这个预训练词向量模型中，一共有260万词汇量，如果全部使用在分类问题上会很浪费计算资源，因为我们的训练样本很小，一共只有4k，如果我们有100k，200k甚至更多的训练样本时，在分类问题上可以考虑减少使用的词汇量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只使用前20000个词\n",
    "num_words = 50000\n",
    "# 初始化embedding_matrix，之后在keras上进行应用\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "# embedding_matrix为一个 [num_words，embedding_dim] 的矩阵\n",
    "# 维度为 50000 * 300\n",
    "for i in range(num_words):\n",
    "    embedding_matrix[i,:] = cn_model[cn_model.index2word[i]]\n",
    "embedding_matrix = embedding_matrix.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查index是否对应，\n",
    "# 输出300意义为长度为300的embedding向量一一对应\n",
    "np.sum( cn_model[cn_model.index2word[333]] == embedding_matrix[333] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 300)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding_matrix的维度，\n",
    "# 这个维度为keras的要求，后续会在模型中用到\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**padding（填充）和truncating（修剪）**  \n",
    "我们把文本转换为tokens（索引）之后，每一串索引的长度并不相等，所以为了方便模型的训练我们需要把索引的长度标准化，上面我们选择了236这个可以涵盖95%训练样本的长度，接下来我们进行padding和truncating，我们一般采用'pre'的方法，这会在文本索引的前面填充0，因为根据一些研究资料中的实践，如果在文本索引后面填充0的话，会对模型造成一些不良影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行padding和truncating， 输入的train_tokens是一个list\n",
    "# 返回的train_pad是一个numpy array\n",
    "train_pad = pad_sequences(train_tokens, maxlen=max_tokens,\n",
    "                            padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超出五万个词向量的词用0代替\n",
    "train_pad[ train_pad>=num_words ] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 926, 769,\n",
       "       156,  12])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可见padding之后前面的tokens全变成0，文本在最后面\n",
    "train_pad[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备target向量，前989样本为1，后2000为0\n",
    "train_target = np.concatenate( (np.ones(641),np.zeros(348)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行训练和测试样本的分割\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90%的样本用来训练，剩余10%用来测试\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_pad,\n",
    "                                                    train_target,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            闲聊生活学习\n",
      "class:  1.0\n"
     ]
    }
   ],
   "source": [
    "# 查看训练样本，确认无误\n",
    "print(reverse_tokens(X_train[35]))\n",
    "print('class: ',y_train[35])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们用keras搭建LSTM模型，模型的第一层是Embedding层，只有当我们把tokens索引转换为词向量矩阵之后，才可以用神经网络对文本进行处理。\n",
    "keras提供了Embedding接口，避免了繁琐的稀疏矩阵操作。   \n",
    "在Embedding层我们输入的矩阵为：$$(batchsize, maxtokens)$$\n",
    "输出矩阵为： $$(batchsize, maxtokens, embeddingdim)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用LSTM对样本进行分类\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# 模型第一层为embedding\n",
    "model.add(Embedding(num_words,\n",
    "                    embedding_dim,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_tokens,\n",
    "                    trainable=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Bidirectional(LSTM(units=32, return_sequences=True)))\n",
    "model.add(LSTM(units=16, return_sequences=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**构建模型**  \n",
    "我在这个教程中尝试了几种神经网络结构，因为训练样本比较少，所以我们可以尽情尝试，训练过程等待时间并不长：  \n",
    "**GRU：**如果使用GRU的话，测试样本可以达到87%的准确率，但我测试自己的文本内容时发现，GRU最后一层激活函数的输出都在0.5左右，说明模型的判断不是很明确，信心比较低，而且经过测试发现模型对于否定句的判断有时会失误，我们期望对于负面样本输出接近0，正面样本接近1而不是都徘徊于0.5之间。  \n",
    "**BiLSTM：**测试了LSTM和BiLSTM，发现BiLSTM的表现最好，LSTM的表现略好于GRU，这可能是因为BiLSTM对于比较长的句子结构有更好的记忆，有兴趣的朋友可以深入研究一下。  \n",
    "Embedding之后第，一层我们用BiLSTM返回sequences，然后第二层16个单元的LSTM不返回sequences，只返回最终结果，最后是一个全链接层，用sigmoid激活函数输出结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU的代码\n",
    "# model.add(GRU(units=32, return_sequences=True))\n",
    "# model.add(GRU(units=16, return_sequences=True))\n",
    "# model.add(GRU(units=4, return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# 我们使用adam以0.001的learning rate进行优化\n",
    "optimizer = Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 15, 300)           15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 15, 64)            85248     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                5184      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,090,449\n",
      "Trainable params: 90,449\n",
      "Non-trainable params: 15,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 我们来看一下模型的结构，一共90k左右可训练的变量\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立一个权重的存储点\n",
    "path_checkpoint = 'sentiment_checkpoint.keras'\n",
    "checkpoint = ModelCheckpoint(filepath=path_checkpoint, monitor='val_loss',\n",
    "                                      verbose=1, save_weights_only=True,\n",
    "                                      save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试加载已训练模型\n",
    "try:\n",
    "    model.load_weights(path_checkpoint)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义early stoping如果3个epoch内validation loss没有改善则停止训练\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自动降低learning rate\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                       factor=0.1, min_lr=1e-5, patience=0,\n",
    "                                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义callback函数\n",
    "callbacks = [\n",
    "    earlystopping, \n",
    "    checkpoint,\n",
    "    lr_reduction\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 801 samples, validate on 89 samples\n",
      "WARNING:tensorflow:From c:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "768/801 [===========================>..] - ETA: 0s - loss: 0.6677 - acc: 0.6367\n",
      "Epoch 00001: val_loss improved from inf to 0.59371, saving model to sentiment_checkpoint.keras\n",
      "801/801 [==============================] - 3s 4ms/sample - loss: 0.6640 - acc: 0.6355 - val_loss: 0.5937 - val_acc: 0.7416\n",
      "Epoch 2/20\n",
      "768/801 [===========================>..] - ETA: 0s - loss: 0.6103 - acc: 0.6875\n",
      "Epoch 00002: val_loss improved from 0.59371 to 0.57703, saving model to sentiment_checkpoint.keras\n",
      "801/801 [==============================] - 1s 862us/sample - loss: 0.6082 - acc: 0.6891 - val_loss: 0.5770 - val_acc: 0.7303\n",
      "Epoch 3/20\n",
      "768/801 [===========================>..] - ETA: 0s - loss: 0.5847 - acc: 0.6706\n",
      "Epoch 00003: val_loss improved from 0.57703 to 0.56270, saving model to sentiment_checkpoint.keras\n",
      "801/801 [==============================] - 1s 920us/sample - loss: 0.5830 - acc: 0.6704 - val_loss: 0.5627 - val_acc: 0.7191\n",
      "Epoch 4/20\n",
      "768/801 [===========================>..] - ETA: 0s - loss: 0.5560 - acc: 0.6979- ETA: 0s - loss: 0.5652 - acc: 0.\n",
      "Epoch 00004: val_loss improved from 0.56270 to 0.54848, saving model to sentiment_checkpoint.keras\n",
      "801/801 [==============================] - 1s 957us/sample - loss: 0.5537 - acc: 0.7041 - val_loss: 0.5485 - val_acc: 0.7528\n",
      "Epoch 5/20\n",
      "768/801 [===========================>..] - ETA: 0s - loss: 0.5128 - acc: 0.7253\n",
      "Epoch 00005: val_loss improved from 0.54848 to 0.52598, saving model to sentiment_checkpoint.keras\n",
      "801/801 [==============================] - 1s 940us/sample - loss: 0.5102 - acc: 0.7266 - val_loss: 0.5260 - val_acc: 0.7753\n",
      "Epoch 6/20\n",
      "768/801 [===========================>..] - ETA: 0s - loss: 0.4658 - acc: 0.7943\n",
      "Epoch 00006: val_loss did not improve from 0.52598\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "801/801 [==============================] - 1s 915us/sample - loss: 0.4643 - acc: 0.7940 - val_loss: 0.5326 - val_acc: 0.7640\n",
      "Epoch 7/20\n",
      "768/801 [===========================>..] - ETA: 0s - loss: 0.4463 - acc: 0.8021\n",
      "Epoch 00007: val_loss improved from 0.52598 to 0.52434, saving model to sentiment_checkpoint.keras\n",
      "801/801 [==============================] - 1s 978us/sample - loss: 0.4470 - acc: 0.8015 - val_loss: 0.5243 - val_acc: 0.7528\n",
      "Epoch 8/20\n",
      "768/801 [===========================>..] - ETA: 0s - loss: 0.4311 - acc: 0.8021\n",
      "Epoch 00008: val_loss did not improve from 0.52434\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "801/801 [==============================] - 1s 708us/sample - loss: 0.4278 - acc: 0.8040 - val_loss: 0.5339 - val_acc: 0.7753\n",
      "Epoch 9/20\n",
      "768/801 [===========================>..] - ETA: 0s - loss: 0.4273 - acc: 0.8047\n",
      "Epoch 00009: val_loss did not improve from 0.52434\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "801/801 [==============================] - 1s 719us/sample - loss: 0.4306 - acc: 0.8027 - val_loss: 0.5330 - val_acc: 0.7753\n",
      "Epoch 10/20\n",
      "768/801 [===========================>..] - ETA: 0s - loss: 0.4313 - acc: 0.8008\n",
      "Epoch 00010: val_loss did not improve from 0.52434\n",
      "801/801 [==============================] - 1s 709us/sample - loss: 0.4288 - acc: 0.8040 - val_loss: 0.5308 - val_acc: 0.7528\n",
      "Epoch 00010: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23d1554eba8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 开始训练\n",
    "model.fit(X_train, y_train,\n",
    "          validation_split=0.1, \n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**结论**  \n",
    "我们首先对测试样本进行预测，得到了还算满意的准确度。  \n",
    "之后我们定义一个预测函数，来预测输入的文本的极性，可见模型对于否定句和一些简单的逻辑结构都可以进行准确的判断。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 505us/sample - loss: 0.4871 - acc: 0.7273\n",
      "Accuracy:72.73%\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test, y_test)\n",
    "print('Accuracy:{0:.2%}'.format(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    print(text)\n",
    "    # 去标点\n",
    "    text = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\",text)\n",
    "    # 分词\n",
    "    cut = jieba.cut(text)\n",
    "    cut_list = [ i for i in cut ]\n",
    "    # tokenize\n",
    "    for i, word in enumerate(cut_list):\n",
    "        try:\n",
    "            cut_list[i] = cn_model.vocab[word].index\n",
    "        except KeyError:\n",
    "            cut_list[i] = 0\n",
    "    # padding\n",
    "    tokens_pad = pad_sequences([cut_list], maxlen=max_tokens,\n",
    "                           padding='pre', truncating='pre')\n",
    "    # 预测\n",
    "    result = model.predict(x=tokens_pad)\n",
    "    coef = result[0][0]\n",
    "    if coef >= 0.5:\n",
    "        print('是一例正面评价','output=%.2f'%coef)\n",
    "    else:\n",
    "        print('是一例负面评价','output=%.2f'%coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我感覺不好\n",
      "是一例负面评价 output=0.16\n",
      "我感覺很好\n",
      "是一例正面评价 output=0.95\n",
      "我被孤立了\n",
      "是一例负面评价 output=0.11\n",
      "我的心情有時候好，有時候不好\n",
      "是一例负面评价 output=0.48\n",
      "我很孤独\n",
      "是一例负面评价 output=0.20\n"
     ]
    }
   ],
   "source": [
    "test_list = [\n",
    "    '我感覺不好',\n",
    "    '我感覺很好',\n",
    "    '我被孤立了',\n",
    "    '我的心情有時候好，有時候不好',\n",
    "    '我很孤独'\n",
    "]\n",
    "for text in test_list:\n",
    "    predict_sentiment(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**错误分类的文本**\n",
    "经过查看，发现错误分类的文本的含义大多比较含糊，就算人类也不容易判断极性，如index为101的这个句子，好像没有一点满意的成分，但这例子评价在训练样本中被标记成为了正面评价，而我们的模型做出的负面评价的预测似乎是合理的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.T[0]\n",
    "y_pred = [1 if p>= 0.5 else 0 for p in y_pred]\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出错误分类的索引\n",
    "misclassified = np.where( y_pred != y_actual )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "# 输出所有错误分类的索引\n",
    "len(misclassified)\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         我会买那个诚恳的人\n",
      "预测的分类 1\n",
      "实际的分类 1.0\n"
     ]
    }
   ],
   "source": [
    "# 我们来找出错误分类的样本看看\n",
    "idx=85\n",
    "print(reverse_tokens(X_test[idx]))\n",
    "print('预测的分类', y_pred[idx])\n",
    "print('实际的分类', y_actual[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          悲惨的不被理解\n",
      "预测的分类 0\n",
      "实际的分类 0.0\n"
     ]
    }
   ],
   "source": [
    "idx=1\n",
    "print(reverse_tokens(X_test[idx]))\n",
    "print('预测的分类', y_pred[idx])\n",
    "print('实际的分类', y_actual[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
