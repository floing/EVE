{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries Needed**  \n",
    "numpy\n",
    "jieba\n",
    "gensim\n",
    "tensorflow\n",
    "matplotlib\n",
    "sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import jieba # 结巴分词\n",
    "# gensim用来加载预训练word vector\n",
    "from gensim.models import KeyedVectors\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pretrained Word Vectors**  \n",
    "使用了北京师范大学中文信息处理研究所与中国人民大学 DBIIR 实验室的研究者开源的Chinese-Word-Vectors：  \n",
    "https://github.com/Embedding/Chinese-Word-Vectors  \n",
    "word2vec的文章：  \n",
    "https://zhuanlan.zhihu.com/p/26306795  \n",
    "我们使用了\"chinese-word-vectors\"知乎Word+Ngram的词向量，可以从上面github链接下载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用gensim加载预训练中文分词embedding\n",
    "cn_model = KeyedVectors.load_word2vec_format('../sgns.zhihu.bigram',binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Vectors Model**  \n",
    "在这个词向量模型里，每一个词是一个索引，对应的是一个长度为300的向量。LSTM并不能直接处理汉字文本，需要先进行分次并把词汇转换为词向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词向量的长度为300\n"
     ]
    }
   ],
   "source": [
    "# 每一个词都对应一个长度为300的向量\n",
    "embedding_dim = cn_model['孔子'].shape[0]\n",
    "print('词向量的长度为{}'.format(embedding_dim))\n",
    "# cn_model['孔子']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.521646"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算相似度\n",
    "cn_model.similarity('孔子', '庄子')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('我国', 0.6130719184875488),\n",
       " ('天朝', 0.5357025861740112),\n",
       " ('美国', 0.5048182010650635),\n",
       " ('中国人', 0.5000995993614197),\n",
       " ('本国', 0.4976556897163391),\n",
       " ('印度', 0.49548032879829407),\n",
       " ('日本', 0.491807758808136),\n",
       " ('国内', 0.4640890955924988),\n",
       " ('大陆', 0.4627026915550232),\n",
       " ('中华民族', 0.43461209535598755),\n",
       " ('外国', 0.43234753608703613),\n",
       " ('周边国家', 0.4288373291492462),\n",
       " ('台湾地区', 0.427590012550354),\n",
       " ('韩国', 0.42619460821151733),\n",
       " ('东亚国家', 0.42446058988571167),\n",
       " ('蒙古国', 0.42360609769821167),\n",
       " ('亚洲', 0.4225274920463562),\n",
       " ('亚洲各国', 0.4225262403488159),\n",
       " ('欧州', 0.4184926748275757),\n",
       " ('国人', 0.4143391251564026)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 找出最相近的词，余弦相似度\n",
    "cn_model.most_similar(positive=['中国'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在 孔丘 圣人 孔子 孟子 孔子 荀子 中:\n",
      "不是同一类别的词为: 圣人\n"
     ]
    }
   ],
   "source": [
    "# 找出不同的词\n",
    "test_words = '孔丘 圣人 孔子 孟子 孔子 荀子'\n",
    "test_words_result = cn_model.doesnt_match(test_words.split())\n",
    "print('在 '+test_words+' 中:\\n不是同一类别的词为: %s' %test_words_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('劈腿', 0.5849199295043945),\n",
       " ('婚外情', 0.5557921528816223),\n",
       " ('偷情', 0.5555664300918579),\n",
       " ('外遇', 0.5458645820617676),\n",
       " ('再婚', 0.5422405004501343),\n",
       " ('未婚先孕', 0.5357398986816406),\n",
       " ('隐婚', 0.5257365703582764),\n",
       " ('离婚', 0.524539053440094),\n",
       " ('马蓉', 0.5239365696907043),\n",
       " ('通奸', 0.5222055912017822)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cn_model.most_similar(positive=['女人','出轨'], negative=['男人'], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 样本存放于两个文件夹中，分别为正面评价文件夹'pos'和负面评价文件夹'neg'\n",
    "# 每个文件夹中有txt文件，每个文件中是一例评价\n",
    "import os\n",
    "pos_txts = os.listdir('Questionnaire Review/pos')\n",
    "neg_txts = os.listdir('Questionnaire Review/neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总共: 989\n"
     ]
    }
   ],
   "source": [
    "print('样本总共: '+ str(len(pos_txts) + len(neg_txts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现在我们将所有的评价内容放置到一个list里\n",
    "train_texts_orig = []\n",
    "for i in range(len(pos_txts)):\n",
    "    with open('Questionnaire Review/pos/'+pos_txts[i], 'r', errors='ignore') as f:\n",
    "        text = f.read().strip()\n",
    "        train_texts_orig.append(text)\n",
    "        f.close()\n",
    "for i in range(len(neg_txts)):\n",
    "    with open('Questionnaire Review/neg/'+neg_txts[i], 'r', errors='ignore') as f:\n",
    "        text = f.read().strip()\n",
    "        train_texts_orig.append(text)\n",
    "        f.close()\n",
    "# 添加完所有样本之后，train_texts_orig为一个含有文本的list，其中先是正面评价，后为负面评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['差不多的意见',\n",
       " '合理情况下得到赞同的意见，与大多人观念相反时得到反对意见',\n",
       " '我的一生',\n",
       " '平凡的平淡的',\n",
       " '有趣的',\n",
       " '坎坷',\n",
       " 'interest',\n",
       " '我的一生',\n",
       " '美好的',\n",
       " '干了一番惊天动地的事情，但最后回归宁静，满足，死而无憾',\n",
       " '这一生过的很圆满，但我并不满意',\n",
       " '平凡又令人震撼的',\n",
       " '一般而言，自己的意见都会被别人认可，尤其是和文学鉴赏以及和学习、艺术相关的项目',\n",
       " '我的',\n",
       " '幸福美满',\n",
       " '人生都是丰富有趣的 不管是顺境逆境',\n",
       " '完美',\n",
       " '我觉得这一生是可以创造无限可能的。',\n",
       " '丰富，坎坷又令人感到幸福的',\n",
       " '问那个人怎么想的',\n",
       " '反驳',\n",
       " '尊重并理解这个人的想法，从中再次思考丰满自己的看法，并表达出来。',\n",
       " '自己想想不能对别人发脾气',\n",
       " '反对或肯定的意见',\n",
       " '我会开始argue',\n",
       " '打他',\n",
       " '激烈的反驳他',\n",
       " '跟他打架',\n",
       " '君子和而不同。梨园事者，非大义也。谨守恭宽信敏惠五字可也。',\n",
       " 'let her go',\n",
       " '辩论进行，但是接受结果，因为不关我事（现实上）',\n",
       " '争论，尝试说服所有人',\n",
       " '问他为什么这么觉得',\n",
       " '我会骂那个人',\n",
       " '尚需商榷',\n",
       " '发表言论',\n",
       " '跟那个人争论',\n",
       " '先思考利弊并反驳',\n",
       " '我会用Evidence和lines of reasoning 将他辩驳的哑口无言',\n",
       " '听他的理由，然后跟他说明自己的理由',\n",
       " '打他',\n",
       " '理性发表自己看法',\n",
       " '听取他的看法在提出自己的看法',\n",
       " '暴打他',\n",
       " '坚持自己的意见，但不妨碍他的选择',\n",
       " 'hh',\n",
       " '尊重那个人的意见，但也要表达自己的意见',\n",
       " '尝试用他的角度看问题',\n",
       " '尊重他的看法 並說出我的想法',\n",
       " '君子和而不同',\n",
       " '我会先了解他为什么会这样说，理由是什么。然后再对比我的理由，如果我觉得我是对的，那么我会尝试去说服他。',\n",
       " '和他聊天说自己想法',\n",
       " '我会argue啊哈哈哈哈哈哈哈哈哈哈哈',\n",
       " '放纵',\n",
       " '打他',\n",
       " '千万不要沉迷于水群忘记了核心矛盾把\"他\"变成\"她\"，然后睡服\"她\"，让\"她\"不要走',\n",
       " '有些赞成，有些反对',\n",
       " '对喷',\n",
       " '试着说服他和我统一战线',\n",
       " '好好说明为什么我不同意',\n",
       " '和他交流想法，或许他的说法有所可取',\n",
       " '娱乐八卦，好友聊天',\n",
       " '吃鸡',\n",
       " '日常',\n",
       " '工作，学习，生活',\n",
       " '八卦',\n",
       " '影视剧、动漫、小说、漫画、政治、传媒',\n",
       " '可能会被采纳',\n",
       " '任何',\n",
       " '什么都有',\n",
       " '学习and男人',\n",
       " '游戏',\n",
       " '学习',\n",
       " '鞋子衣服 好听的歌 日常',\n",
       " 'LOL',\n",
       " '游戏，学习，和吃的',\n",
       " '日常生活，',\n",
       " '日常聊天的内容',\n",
       " '很好',\n",
       " '学习，生活，娱乐，新闻，世界，学校',\n",
       " '作业完成情况，假期旅行，Party筹办',\n",
       " '要看和谁聊天，通常为日常生活和学习',\n",
       " '生活中发生的快乐沙雕事情',\n",
       " '日常',\n",
       " '学习 娱乐',\n",
       " '学习，生活',\n",
       " '游戏或友情',\n",
       " '日常生活',\n",
       " '作业 生活经历',\n",
       " '题目很奇怪，当然有反对意见，但是会探讨各种方案取最优',\n",
       " '娱乐，日常生活',\n",
       " '日常',\n",
       " '生活学校',\n",
       " '学习 八卦',\n",
       " '大佬の日常',\n",
       " '八卦',\n",
       " '生活',\n",
       " '学习与生活',\n",
       " '学习，女性朋友',\n",
       " '日常生活，工作',\n",
       " '会遇到在我的意见基础上进行更好的补充的意见',\n",
       " '日常生活与爱好',\n",
       " '日常或学科专业',\n",
       " '都有',\n",
       " '日常',\n",
       " '日常生活，共同的兴趣爱好，学习',\n",
       " '娱乐和生活，或许游戏',\n",
       " '我通常在和朋友讨论最近的新闻',\n",
       " '学习和日常',\n",
       " '羞羞的内容',\n",
       " '啥都有',\n",
       " '赞同',\n",
       " '赞同或不赞同',\n",
       " '感兴趣的内容',\n",
       " '视频素材（b站up主不容易）',\n",
       " '我一般都在和同学聊家常，去吃什么，去玩什么各种',\n",
       " '其实跟聊天的对象有关系学习，社会，爱好，分享些有趣的事情…… 很杂就对了',\n",
       " '我可以改掉自己的坏习惯，并且拥有一些好习惯',\n",
       " '身体健康 快快乐乐',\n",
       " '期待',\n",
       " '去我想去的地方',\n",
       " '表白',\n",
       " '出去放纵一天',\n",
       " '会遇到在我的意见基础上进行更好的补充的意见',\n",
       " '开瓶香槟',\n",
       " '啥都做',\n",
       " '我会去全世界周游',\n",
       " '成为神仙',\n",
       " '去一次房车旅行或者要一笔资金做球鞋小买卖 试一下感觉',\n",
       " '买一辆超跑',\n",
       " '想做什么就做什么',\n",
       " '学会时间穿梭',\n",
       " '烧作业',\n",
       " '会实现吗，那我要考AP第一名',\n",
       " '反对或者赞成',\n",
       " '嗨一整天',\n",
       " '购物',\n",
       " '和同学们出去唱K/去游乐场玩/去山上露营',\n",
       " '可以陪父母过完整一天',\n",
       " '我会去跳伞',\n",
       " '去旅行',\n",
       " '去玩',\n",
       " '拿回被没收的电脑',\n",
       " '在广州建一个鲨鱼馆',\n",
       " '好好学习天天向上',\n",
       " '会被赞同',\n",
       " '玩',\n",
       " '我爱我女票（逃',\n",
       " '要有钱的话。。。组建一台一箱两机的电脑(一大一小两个主板，大板上双路e5＋2080跑运算跑渲染，小板上赛扬当nas)',\n",
       " '谈恋爱吖，希望对方是个得力助手',\n",
       " '世界和平 少點疾病',\n",
       " '为所欲为？造作',\n",
       " '获得一只女票',\n",
       " '去想去的地方旅游',\n",
       " '我会吃蛋糕',\n",
       " '弄一个无限银行卡',\n",
       " '我觉得我的意见应该被时常采纳，如果我的意见被反驳了的话我可能会生气。',\n",
       " '我会成为伟大的神，全知全听全能的那种上任第一件事是把人类变成独雌繁殖',\n",
       " '出去玩',\n",
       " '找朋友',\n",
       " '大吃一顿',\n",
       " '蹦极',\n",
       " '给自己买礼物',\n",
       " '信他',\n",
       " '买',\n",
       " '再看看，其他公司',\n",
       " '诚恳的',\n",
       " '？一般不会遇到意见',\n",
       " '买态度好的',\n",
       " '当然是买这个人的票',\n",
       " '卖给诚恳的第一个人',\n",
       " '买',\n",
       " '我会买那个诚恳的人',\n",
       " '买',\n",
       " '选择诚恳的人',\n",
       " '买啊。',\n",
       " '买前面那个人的票',\n",
       " '买诚恳的人的',\n",
       " '我觉得可能会因为我提的意见太有建设性，思想性。大家都不会对我的意见有意见',\n",
       " '当然是买诚恳的人的票啦',\n",
       " '当然是买啊',\n",
       " '问清楚',\n",
       " '买第一个人的票',\n",
       " '买便宜且诚恳的',\n",
       " '选择从诚恳的人那里买票',\n",
       " '买第一个人的票',\n",
       " '买',\n",
       " '答应',\n",
       " '正规去买票',\n",
       " '他们肯定会接受我的意见',\n",
       " '我会去买第一个人的票',\n",
       " '买第一个人的',\n",
       " '我会选择他售出的票，因为社会上大家对于这类似的人都会更加接受',\n",
       " '买他的票',\n",
       " '直接买',\n",
       " '买便宜的',\n",
       " '买诚恳的那个人的票',\n",
       " '去很诚恳的人那里',\n",
       " '必买啊',\n",
       " '买那个诚恳的人的票',\n",
       " '与众不同的意见',\n",
       " '选择诚恳的',\n",
       " '买票',\n",
       " '表扬他',\n",
       " '就买这个人的',\n",
       " '我会很开心，然后告诉他下次别这样，因为有可能因为客户投诉而失去工作',\n",
       " '选择第一个',\n",
       " '当然是第一个人啊',\n",
       " '买',\n",
       " '在车站买',\n",
       " '像很诚恳的人买票，不理会挑畔的人',\n",
       " '好的意见',\n",
       " '选择正当合理的',\n",
       " '选择诚恳的人',\n",
       " '购买第一个人的',\n",
       " '买',\n",
       " 'first one',\n",
       " '购买诚恳的人的票，给点小费',\n",
       " '选服务态度好的',\n",
       " '我会找第一个人买票',\n",
       " '买这个人的票',\n",
       " '买诚恳哪个',\n",
       " '改善的意见',\n",
       " '赞成',\n",
       " '选择诚恳的',\n",
       " '欣然接受',\n",
       " '买',\n",
       " '我会很不爽那个挑衅的人，同时为他感到叹息。',\n",
       " '选择更真诚的卖家',\n",
       " '谢谢',\n",
       " '谢谢他啊',\n",
       " '谢谢 问他怎么知道',\n",
       " '说谢谢',\n",
       " '谢谢',\n",
       " '和自己相辅相成的意见',\n",
       " '感谢ta',\n",
       " '谢谢',\n",
       " '道谢并接过铅笔',\n",
       " '谢谢',\n",
       " '感谢他',\n",
       " '谢谢他',\n",
       " '说声谢谢然后接过铅笔',\n",
       " '谢之。',\n",
       " '接受，谢谢他，下课再跟他说详细情况。',\n",
       " '谢谢',\n",
       " '汇总和其他人的意见',\n",
       " '说：“哇！这么好的嘛！谢谢！”',\n",
       " '谢谢他，在内心感叹他细心',\n",
       " '谢谢',\n",
       " '谢谢谢谢！',\n",
       " '谢谢他',\n",
       " '说谢谢表达感谢和善意',\n",
       " '谢谢（thanks）',\n",
       " '说:\"谢谢\"，十分感动',\n",
       " '说谢谢',\n",
       " '感谢并事后还他',\n",
       " '赞成',\n",
       " '说谢谢',\n",
       " '说谢谢',\n",
       " '感谢他',\n",
       " '感激他/她，并且询问他是怎么知道我完蛋了的',\n",
       " '谢谢',\n",
       " '问他为什么给我',\n",
       " '接受说谢谢',\n",
       " '谢谢',\n",
       " '接过来',\n",
       " '接着 说谢谢',\n",
       " '还可以但是要修改',\n",
       " '感谢并接受',\n",
       " '谢谢他',\n",
       " '欣然接受并说声谢谢',\n",
       " '拿下并且说谢谢',\n",
       " '谢谢她',\n",
       " '说谢谢你',\n",
       " '谢谢他',\n",
       " '说谢谢并且用，下一次帮助他',\n",
       " '谢谢他，并非常开心地使用',\n",
       " '谢谢他（她）',\n",
       " 'emmm有赞同也有反对的吧',\n",
       " '接过并感谢',\n",
       " '谢谢大佬！（接过）',\n",
       " '再问他借块橡皮',\n",
       " '谢谢然后拿走',\n",
       " '说“谢谢”',\n",
       " '接受',\n",
       " '接过 并向他说谢谢',\n",
       " '謝謝對方',\n",
       " '拿来用并表示感谢',\n",
       " '感谢他',\n",
       " '我希望我的意见不被收到偏心对待。如果我的意见好就可以如果不好就属实不行，我选择接受。',\n",
       " '哇！谢谢！它日必将偿还',\n",
       " '接过来并道谢',\n",
       " '谢谢',\n",
       " '谢谢并接受',\n",
       " '接',\n",
       " '我觉得他很善良，会跟他说声谢谢。',\n",
       " '接过来 thank you',\n",
       " '接受',\n",
       " '接过来用',\n",
       " '感谢',\n",
       " '想法有创意 但是需要修改得更加可实行',\n",
       " '我会接受一旁的人的铅笔',\n",
       " '谢谢',\n",
       " '谢谢他',\n",
       " '谢谢',\n",
       " '说 谢谢你，我下课还',\n",
       " '拿上',\n",
       " '拿过来说声谢谢哥',\n",
       " '谢谢',\n",
       " '乐意接受',\n",
       " '收下然后说谢谢',\n",
       " '被讨论是否合理',\n",
       " '说谢谢',\n",
       " '谢谢',\n",
       " '谢谢他',\n",
       " '感谢他',\n",
       " '谢谢你',\n",
       " '接过来说谢谢',\n",
       " '收下并感谢',\n",
       " '我会跟他说声谢谢，写完下课还给他。',\n",
       " '道谢，感激地接受他的帮助',\n",
       " '来张自拍',\n",
       " '他们会肯定我的意见',\n",
       " '我去海港城吃饭',\n",
       " '真好 拍照发给朋友',\n",
       " '很爽',\n",
       " '好幸福',\n",
       " '很爽',\n",
       " '爽并兴奋',\n",
       " '很漂亮',\n",
       " '好好看',\n",
       " '升起的烟花，从下面看？还是从侧面看？',\n",
       " '好啊',\n",
       " '大家都会觉得我特牛逼！',\n",
       " '把它吃了',\n",
       " '真美',\n",
       " '这个时候身边应该有苏立锦',\n",
       " '要看我旁白是谁',\n",
       " '好看',\n",
       " '很开心，但也会想有没有一些更环保的方法',\n",
       " 'excited，enthusiastic',\n",
       " '非常壮观',\n",
       " '很漂亮',\n",
       " '好漂亮',\n",
       " '很美',\n",
       " '叫哈利波特',\n",
       " '很高兴',\n",
       " '很好',\n",
       " '很好看',\n",
       " '很有意思',\n",
       " '惬意',\n",
       " '很美',\n",
       " '人生圆满',\n",
       " '很漂亮',\n",
       " '如果能和他/她一起就好了',\n",
       " '很幸福',\n",
       " '说冷笑话，并撸一把他的秃头',\n",
       " '人多，但是很好看',\n",
       " '好漂亮QAQ',\n",
       " '享受當下',\n",
       " '很浪漫，',\n",
       " '能和喜欢的人一起就最好了',\n",
       " '浪漫',\n",
       " '生活过得去',\n",
       " '女朋友应该在身边',\n",
       " '十分绚丽，浪漫，热闹',\n",
       " '我觉得我需要一些人来分享我的乐趣',\n",
       " '劝说，并抱住文件',\n",
       " '很爽',\n",
       " 'cool',\n",
       " '很嗨',\n",
       " '维多利亚港的比较好看吧',\n",
       " '给其他人看看帮忙提供修改意见',\n",
       " '再看看修改',\n",
       " '再看看 等到时间了再交',\n",
       " '修改',\n",
       " '给别人看',\n",
       " '把作品给家人和朋友看，问他们的意见并进行修改',\n",
       " '邓布利多怎么可能打不过巨怪如果邓布利多不在的话呼神护卫应该有用吧实在不行打不过抢了东西跑到走廊上找麦格教授啊',\n",
       " '再看一遍',\n",
       " '邀请朋友阅读全文并检查有没有吃书的部分',\n",
       " '看一遍',\n",
       " '让其他人修改',\n",
       " '再检查一遍',\n",
       " '请别的人阅读 并问他们需要改进的地方再自己思考 再进一步修改',\n",
       " '精益求精，此君子之道也。',\n",
       " '用这个时间再读一次，做一次最终修改',\n",
       " '再浏览一遍有没有什么要改的',\n",
       " '便去旅游个人，便修改',\n",
       " '劝说',\n",
       " '一遍一遍的看，看看措辞是否需要修改',\n",
       " '再看一遍看看有什么不对的',\n",
       " '稍微改改',\n",
       " '重读小说，检查错别字',\n",
       " '再看一遍',\n",
       " '看一遍',\n",
       " '读，修改',\n",
       " '闷在家里使劲修改两天',\n",
       " '重读一遍，看看需要什么改进',\n",
       " '修改',\n",
       " '叫人',\n",
       " '赶紧干',\n",
       " '我会好好修改',\n",
       " '再重新看看 找出还有没有问题',\n",
       " '我会速读一遍，再进行斟酌是否要修改',\n",
       " '继续看一下有什么可以改的',\n",
       " '改啊',\n",
       " '一直修改',\n",
       " '修改',\n",
       " '修改直到deadline',\n",
       " '再检查一遍',\n",
       " '索命咒。',\n",
       " '小修小改',\n",
       " '再看看',\n",
       " '给朋友看寻求建议',\n",
       " '再看看',\n",
       " '继续研究，看有没有其他地方可以修改',\n",
       " '检查语法错误，给Mr.Chromecki过目要一波评价',\n",
       " '整份宣传文案出来',\n",
       " '再看看有没有修改的',\n",
       " '征求别人的意见然后在修改',\n",
       " '找朋友等人士参考',\n",
       " '天命不可违也。上善若水，顺其自然则可矣。',\n",
       " '仔细阅读',\n",
       " '詢問他人意見並作出修改',\n",
       " '全力冲刺，精益求精',\n",
       " '再看看或者向别人询问意见',\n",
       " '多检查翻看是否有错误，给他人看看，让别人提提意见',\n",
       " '挤出时间来写',\n",
       " '我会在这两天的时间里面进行最后的排查修改，因为我是一个完美主义者，希望在有限的时间内可以尽量完善。',\n",
       " '欣赏',\n",
       " '边看边修改',\n",
       " '完整读一遍自己作品，找漏洞',\n",
       " '把那几个东西用魔力移走到其他房间',\n",
       " '我会在看一遍检查细节',\n",
       " '改得出其不意',\n",
       " '让别人给意见',\n",
       " '在检查一下有没有什么需要改的地方',\n",
       " '给朋友看并让他说写comment',\n",
       " '提交',\n",
       " '维他入我心，改动随便拼',\n",
       " '检查错别字',\n",
       " '继续修改跟进',\n",
       " '检查错别字等等，再找其他人帮我阅读纠正错误',\n",
       " '别人对技术层面，或者思维深度广度的一些探究问题',\n",
       " '用魔法把这些物品转移到尽量远的地方',\n",
       " '检查',\n",
       " '再看一遍，再修改一下',\n",
       " '修改',\n",
       " '校对错别字，让亲人阅读一部分并评价',\n",
       " '大概把作品读一遍，把设定有误与有提成空间的地方稍作修改',\n",
       " '发给好朋友看看 有没有修改意见',\n",
       " '我会仔细修改小说，努力做到完美',\n",
       " '智慧',\n",
       " '和别人一起把巨怪打倒',\n",
       " '醒来',\n",
       " '找人一起抗衡',\n",
       " '扑救',\n",
       " '醒来',\n",
       " '和他谈',\n",
       " '校长办公室该有机关的吧啊喂',\n",
       " '我希望可以在我的能力范围之内尽量保护物品，同时找到我的伙伴哈利。',\n",
       " '心平气和地与他谈判，用很友好的态度说服他',\n",
       " '跌宕起伏',\n",
       " '漫长的',\n",
       " '时而欢乐时而痛苦懊悔的',\n",
       " '她是一个天真无邪的人',\n",
       " '打110',\n",
       " '普通而有意义的',\n",
       " '我最盼望得到的一生',\n",
       " '复杂的',\n",
       " '美好的的',\n",
       " '自己的',\n",
       " '大起大落的故事线',\n",
       " '看上去平淡与忧伤实则波澜壮丽',\n",
       " '圆满的',\n",
       " '经过努力奋斗后得来的令这个人满足的一生',\n",
       " '安全平靜的',\n",
       " '找哈利波特',\n",
       " '我的吧，或他人的',\n",
       " '我自己',\n",
       " '有意思的一生',\n",
       " '平静的',\n",
       " '我的世界',\n",
       " '我',\n",
       " '尝过两个班以上的女孩子的口红的味道的姐姐大人',\n",
       " '充满挑战',\n",
       " '自己的',\n",
       " '很美好的一生',\n",
       " '叫人来',\n",
       " '有明确目标的',\n",
       " 'argue一波',\n",
       " '举例证明自己的观点，努力说服别人',\n",
       " '对此不回应 也不说出自己真实意见 避免纠纷 毕竟粉丝都很疯狂',\n",
       " '理解',\n",
       " '跟他好好地表明自己的看法',\n",
       " '坚持自己的意见但是也不为难别人',\n",
       " '没什么好说的，个人观点',\n",
       " '听听就好',\n",
       " '举例子',\n",
       " '马上呼叫其他人来支援',\n",
       " '据理力争',\n",
       " '询问他的意见',\n",
       " '我会选择倾听意见再发表自己见解',\n",
       " '尝试反驳',\n",
       " '表达我自己的想法',\n",
       " '我不喜欢浪费时间在别人身上',\n",
       " '尊重每个人的意见，做理智粉丝',\n",
       " '通过干货来支撑我的观点，但表示理解他的想法',\n",
       " '我会与那个人开始讲道理，论证这个问题',\n",
       " '对就对咯，各抒己见',\n",
       " '呼叫同学帮忙',\n",
       " '我会同意的',\n",
       " '反驳',\n",
       " '解释 如果解释不通沉默',\n",
       " '找个酒吧，坐下一起谈，我请客',\n",
       " '我不会有这种时候吧，每个人都选择都该被尊重',\n",
       " '我希望他能改变自己的看法，但我会先听他的意见。',\n",
       " '不与他抬杠，思考他说得是否正确再作回应',\n",
       " '八卦，日常琐事',\n",
       " '学习和生活',\n",
       " '关于学习方面的一些内容或者又是一些关于自己身边人的事，或者又是关于一些时事，像B站上面的东西或者鬼畜，反正就是00后比较感兴趣或者又是一些当下比较敏感的话题',\n",
       " '寻找别人的帮助',\n",
       " '任何关心的事情，通常都从新闻或体育（NBA）',\n",
       " '日常生活和学习',\n",
       " '学习',\n",
       " 'everything',\n",
       " '运动 时尚 学习',\n",
       " '分享ins上的美女',\n",
       " 'hi',\n",
       " '娱乐八卦，追星日常',\n",
       " '学术',\n",
       " '游戏打法',\n",
       " '我可能会先用某一种东西让巨怪引开注意，先去把那几个至关重要的物件收好，找一条最近可以从霍洛沃茨校长办公室到达禁地森林最近的路，把巨怪引进森林，再利用森林的地型，或是引到蜘蛛（第二部）的栖息地，让疯狂的食肉蜘蛛解决掉巨怪',\n",
       " '平常发生的事',\n",
       " '从来不在聊天软件上发消息，除非一些十分必要的东西',\n",
       " '日常生活和段子',\n",
       " '正经话题',\n",
       " '有趣的生活',\n",
       " '讨论课题内容',\n",
       " '我经常讨论学的一些内容，包括赛达，托福，以及各种国际课程考试等。',\n",
       " '生活～兴趣',\n",
       " '马克思列宁主义，世界未来可能会爆发的经济危机，广义相对论以及狭义相对论等相关问题',\n",
       " '攻略',\n",
       " '求助',\n",
       " '吃',\n",
       " '日常，感情，八卦',\n",
       " '电子垃圾 道德伦理认同 文化历史 人际关系 情感问题',\n",
       " '日常',\n",
       " '闲聊生活，学习',\n",
       " '日常生活',\n",
       " '各种电影',\n",
       " '学校 生活 八卦',\n",
       " '八卦时事',\n",
       " '学习 生活方面的',\n",
       " '肯定大家都有不同的想法，很难断定',\n",
       " '用魔法转移物品',\n",
       " '为什么要等到生日呢',\n",
       " '让家人和自己一生平安',\n",
       " '去环游世界',\n",
       " '安全环游世界',\n",
       " '表白',\n",
       " '邀请自己喜欢的人和自己最爱的人，其次就是朋友，然后一起包场做一些事',\n",
       " '去看一场Ed Sheeran的演唱会',\n",
       " '汲取万物之理',\n",
       " '找女朋友',\n",
       " '享受生活旅行',\n",
       " '阿瓦达索命',\n",
       " '和女朋友去旅游',\n",
       " '我会去一个陌生的城市游荡，体验一天生活',\n",
       " '实现自己的愿望',\n",
       " '学习 陪家人',\n",
       " '跟女朋友在一块',\n",
       " '和王佳柠在一起',\n",
       " '玩',\n",
       " '上天',\n",
       " '我希望我申请的夏校都能录！',\n",
       " '和亲朋好友一起enjoy',\n",
       " '直接一波Dr.Strange 时间宝石修复，然后把巨怪缩小，然后送给赫敏当宠物，然后继续泡赫敏。',\n",
       " '我会找一个好朋友和我一起出去玩',\n",
       " '買誠懇的人的票',\n",
       " '成交',\n",
       " '买票啊，第一个的',\n",
       " '买第一个人的',\n",
       " '选诚恳的人',\n",
       " '买第一个人的票',\n",
       " '买啊',\n",
       " '买',\n",
       " '买第一个人的票',\n",
       " '跪求大佬帮忙',\n",
       " '选择态度好的',\n",
       " '美',\n",
       " '太好看了吧',\n",
       " '好看',\n",
       " '我觉得烟火比较适合景气的气氛，非常适合旅游。',\n",
       " '很好看',\n",
       " '这世界很美好',\n",
       " '好舒服',\n",
       " '要是我能佐拥侑抱就好了，那画面一定很美',\n",
       " '看和谁一起了',\n",
       " '物品调换，把随手摸得到的差不多的东西的存在与那个东西的存在调换',\n",
       " '哇好漂亮啊',\n",
       " '很漂亮吧【我也不清楚】',\n",
       " '找哈利波特',\n",
       " '相信自己体内有巨大的魔力但只会在牺牲的时候爆发打败巨怪，会毫不犹豫的自己牺牲来保护那些物件',\n",
       " '我会被吓醒',\n",
       " '與小夥伴一起',\n",
       " '从梦中醒来',\n",
       " '大多数都是赞成，极少反对',\n",
       " '移形换影',\n",
       " '溜了谁鸟他',\n",
       " '我会偷偷的把最重要的物件，霍格沃茨的神杖偷偷的带走，然后赶紧联系邓布利多。',\n",
       " '不想抢救',\n",
       " '生命',\n",
       " '将重要物件变成不起眼的小东西',\n",
       " '法力把Dumbledore召唤过来搞他',\n",
       " '召唤哈利波特魔力系统以外的巴拉拉能量，把校长和巨怪都变成漂亮妹子，然后命令她们\"合为一体\"，那些东西是好是坏哪有我看人外少女和马猴烧酒上演春宫大戏重要',\n",
       " '打110',\n",
       " '找别人帮忙',\n",
       " '支持',\n",
       " '找多几个人一起把校长统统石化',\n",
       " '轰轰烈烈',\n",
       " '痛苦并快乐着',\n",
       " '幸福而一帆风顺的',\n",
       " '我自己的一生',\n",
       " '平凡却幸福的',\n",
       " '一开始，这个人给自己的人生开了个挂，带着一部手机全程开后宫',\n",
       " '需要学习的',\n",
       " '完美的',\n",
       " '君子一生，立根原在破岩中，咬定青山不放松。千载不朽、万古流芳，丹心照汉青。',\n",
       " '支持和反对',\n",
       " '美好的并且波澜起伏',\n",
       " '无比的丰富，有着无数喜怒哀乐',\n",
       " '平凡不平庸，有一些小小的波折但是最终很幸福',\n",
       " '经历挫折跌宕',\n",
       " '有始有终，起起落落',\n",
       " '世界上某个人的人生 毕竟梦可以预言',\n",
       " 'depends on我当时心情',\n",
       " '快乐的',\n",
       " '有丰富的经历但是也平安的',\n",
       " '幻想中的',\n",
       " '额，没看懂题',\n",
       " '不知道',\n",
       " '逃',\n",
       " '看看有没有其他的东西转移他的注意力',\n",
       " '投降说服它',\n",
       " '想办法弄晕他？然后再下手',\n",
       " '趁他不注意  偷袭',\n",
       " '有欢笑有悲伤',\n",
       " '遗憾',\n",
       " '悲惨的',\n",
       " '我的前世或下世',\n",
       " '是前世',\n",
       " '噫！阿谀奉承假意承欢者数不胜数，苦口良药逆耳忠言者实少之又少！可知世间不存无影之华耶，余亦非他世之物，岂能不落其中乎？余寒窗铁衾十二载，诗书万卷腹中藏，岂能如尔等口蜜腹剑居心叵测之人所惑！',\n",
       " '碌碌无为而又有点东西',\n",
       " '凄美的而深沉的，一个人逆风追逐却不得而终的故事',\n",
       " '很孤独的',\n",
       " '自己的缩影？',\n",
       " '虚空的，化成碎片消逝在空间里',\n",
       " '无奈而空虚，本来胸怀大志但最终碌碌无为的人生',\n",
       " '一场梦',\n",
       " '学徒',\n",
       " '前世',\n",
       " '痛苦的',\n",
       " '我也不知道啊',\n",
       " '悲剧',\n",
       " '还不错吧.....应该比我好......',\n",
       " '事业有成名利双收，但在晚年不怎么幸运',\n",
       " '荒谬的',\n",
       " '痛苦而平淡的',\n",
       " '荒谬的',\n",
       " '虚无缥缈的',\n",
       " '我好像梦到过',\n",
       " '小康的？（个人觉得在国内不会太开心）',\n",
       " '我看不透这个人的一生，有很多矛盾的地方',\n",
       " '这样有问题',\n",
       " '伤心',\n",
       " '尊重他的说法',\n",
       " '回家',\n",
       " '各有各的看法，我也不能强迫别人想法跟我一致，顺其自然吧',\n",
       " '但其实作为粉丝他干什么都支持',\n",
       " '当做没看到',\n",
       " '尊重他的想法，但是可能在以后不会在跟这个粉丝群有太大互动',\n",
       " '离开他的讨论',\n",
       " '无所谓',\n",
       " '我应该不会怎么办，可能会闷闷不乐一整天吧',\n",
       " '不是很懂题目..',\n",
       " '不理他',\n",
       " '踢他出群',\n",
       " '离开是个人选择，无权干涉。互相尊重不同观点。',\n",
       " '去逼乎上发个问题再写篇头头是道的长的我自己都懒得看的逼乎回答',\n",
       " '无视',\n",
       " '不发表见解',\n",
       " '不理他',\n",
       " '各执己见，每个人有不同的看法',\n",
       " '其实我觉得是对的',\n",
       " '默默走开',\n",
       " '反对的意见',\n",
       " '什么都不说 【每个人想法不同嘛】',\n",
       " '不理会   每个人有不同想法 也有些人只想博得关注  自己喜欢就好',\n",
       " '动漫，留学，毫无意义的沙雕哈哈哈',\n",
       " '无非虚与委蛇而已，市侩无聊。千年以降，皆如此哉！噫！世道变异，神器更替，亦不改于人之本性也。',\n",
       " '不会闲聊，只有有事的时候才聊',\n",
       " '讨论些无聊的话题打发时间',\n",
       " '周末作业的加量以及脱发问题',\n",
       " '色情内容',\n",
       " '不知道，不一定',\n",
       " '智商问题',\n",
       " '反对意见',\n",
       " '哲学与人生',\n",
       " '生活琐事',\n",
       " '杂七麻八',\n",
       " '今天干什么',\n",
       " '我通常在和同学们讨论最近的烦恼',\n",
       " '学会魔法',\n",
       " '学习',\n",
       " '于余之生日，若可有一大能者，尽除戚戚之小人、与天下寒士广厦万间，则纵余其百死其尤未悔耳。',\n",
       " '氪金打游戏',\n",
       " '让生日平静的过去',\n",
       " '被否定或者自己的意见会引起别人不好的回忆，或者又i是别人在我的意见的基础之上完善我的意见或又加创新',\n",
       " '任何事吗？那就睡一天好了',\n",
       " 'sat1600托福120gpa5.0拿到梦校的offer',\n",
       " '准备生日，过生日',\n",
       " '发明一种能直接把知识输送到脑海中的机器',\n",
       " '烧作业',\n",
       " '睡觉',\n",
       " '什么都不做',\n",
       " '什么也不做，等到生日来临',\n",
       " '回到过去',\n",
       " '睡觉',\n",
       " '相反的意见',\n",
       " '托福110',\n",
       " '出门远行，没有人知道我本身的情况',\n",
       " '像往常一样过一个生日',\n",
       " '看书，睡觉，享受人生',\n",
       " '学会读心术',\n",
       " '我希望我的生日可以帮我实现我想实现的东西。',\n",
       " '想做啥做啥吧',\n",
       " '遗忘',\n",
       " '睡一觉',\n",
       " '让自己科科满分',\n",
       " '小组的选题会有分歧',\n",
       " '玩手机',\n",
       " '没看懂',\n",
       " '不买',\n",
       " '买便宜的',\n",
       " '君子刚毅木讷，小人观之，反恶之扭捏作态，不通事理。假意承欢、欺人之不防——此非小人耶？可叹芸芸之不识货也。',\n",
       " '我不管',\n",
       " '我想做，为什么要给',\n",
       " '我会窝在酒店里。我不喜欢出门。',\n",
       " '不怎么办',\n",
       " '选另一个人',\n",
       " '为什么行不通？',\n",
       " '反对',\n",
       " '都询问一遍',\n",
       " '便宜没好货，买贵的',\n",
       " '观察那个人，没有异样就买他的',\n",
       " '找最贵的几个去问清楚情况',\n",
       " '我会暴打那个挑衅的人一顿然后把票拿走',\n",
       " '再看看',\n",
       " '按原价购买',\n",
       " '转头吃饭',\n",
       " '我会掉头走掉，我晕车谢谢',\n",
       " '我会买第二个人的票',\n",
       " '反对',\n",
       " '学习',\n",
       " '尴尬的微笑点头并谢谢他',\n",
       " '谢谢并接过铅笔之后留意TA的行为',\n",
       " '女男的话，不熟不要，熟悉的话，拿走感谢',\n",
       " '我会觉得有些奇怪，但是因为我的桌上没有铅笔盒，所以我可以推测他一定注意了我一段时间，才推断出我没有带笔盒的',\n",
       " '知道那个人暗恋我',\n",
       " '尴尬的收下，晚点还给他',\n",
       " '谢谢他她，然后慢慢留意他',\n",
       " '要可塑橡皮，水笔，油画棒，水彩，色粉，然后说声谢谢',\n",
       " '收下，并说感谢，便询问原因',\n",
       " '不清楚',\n",
       " '问他为什么给我',\n",
       " '问他他是不是从未来来的',\n",
       " '先感谢婉拒再向朋友借',\n",
       " '尴尬接受不并说谢谢',\n",
       " '我会善意地拒绝旁边人的铅笔',\n",
       " '凄凉',\n",
       " '很美很孤独',\n",
       " '烟火璀璨但只存于一瞬间',\n",
       " '孤独',\n",
       " '想学习',\n",
       " '不好的意见',\n",
       " 'typical',\n",
       " '朱门酒肉臭，路有冻死骨。',\n",
       " '想回老家',\n",
       " '为什么我要出来看烟火而不在家里睡觉',\n",
       " '大雾，看不清烟火。觉得惆怅',\n",
       " '孤独',\n",
       " '宁静',\n",
       " '好多人啊',\n",
       " '寂寞',\n",
       " '孤独',\n",
       " '反对意见',\n",
       " '想家',\n",
       " '我好惨，我为什么不回家吃饭',\n",
       " '想家',\n",
       " '生命无常',\n",
       " '这是港大的面试题（逃',\n",
       " '就应该去郊区自己放',\n",
       " '好多人',\n",
       " '人好多',\n",
       " '没去过',\n",
       " '虽然很美，但是还是和亲戚长辈在一起更舒服',\n",
       " '与别人想法不一致',\n",
       " '好孤独',\n",
       " '孤独',\n",
       " '太挤了',\n",
       " '太挤了',\n",
       " '梦',\n",
       " '很孤单',\n",
       " '在外面都不叫过年',\n",
       " '这种美景良辰还不是时候。',\n",
       " '时间流逝与欣赏烟火的愉悦',\n",
       " '我觉得烟火很无聊，看过了，就不会再想看第二次',\n",
       " '各种质疑',\n",
       " '去学习',\n",
       " '好好休息',\n",
       " '不修改了',\n",
       " '不会修改',\n",
       " '不修改',\n",
       " '不修改',\n",
       " '不管了',\n",
       " '出去玩！',\n",
       " '丢在一边，自己去玩',\n",
       " '就这样了',\n",
       " '如何开展',\n",
       " '就这样吧',\n",
       " '毫不犹豫地提交给出版社',\n",
       " '随便看看吧',\n",
       " '不修改',\n",
       " '不改',\n",
       " '不改',\n",
       " '浪',\n",
       " '放弃修改',\n",
       " '不修改',\n",
       " '我会直接上交我的作品',\n",
       " '被不听',\n",
       " '去玩',\n",
       " '最后一次修改，然后放空自己',\n",
       " '递交',\n",
       " '不改了',\n",
       " '弄一份备份瞎改着玩儿',\n",
       " '我懒得修改了，尽量早交。',\n",
       " '或许抢走物品并且逃跑',\n",
       " '我会看着巨怪把这个东西破坏，并微笑着离开',\n",
       " '跑 赶紧跑',\n",
       " '我会努力对抗巨怪，并在这个过程中死亡',\n",
       " '有认同也有抱有疑问的反对观点',\n",
       " '也许我的一生也是像他如此（你问的这个问题取决于每个人梦到什么呀）',\n",
       " '假的',\n",
       " '假的',\n",
       " '假的',\n",
       " '悲惨的',\n",
       " '好难',\n",
       " '孤独的',\n",
       " '充满了绝望的',\n",
       " '我觉得我这一生可能是没有任何意义的，我先进了深深的思考。',\n",
       " '虚假的',\n",
       " '被遭到质疑，受人批判，',\n",
       " '(没看懂问题）',\n",
       " '是一个陌生人的故事',\n",
       " '空虚的',\n",
       " '悲惨的，不被理解',\n",
       " '乏味无趣',\n",
       " '我不会参加讨论，那个成员要不要离开是他的事。而且我从没喜欢过乐队。',\n",
       " '不去理会他',\n",
       " '打爆他',\n",
       " '离开',\n",
       " '放弃谈话',\n",
       " '让他说为什么。不合理的话直接杠他',\n",
       " '相对的反对的意见',\n",
       " '自己一个人难过',\n",
       " '和他激烈争吵',\n",
       " '微斯人，吾谁与归，',\n",
       " '我不鸟他',\n",
       " '心里骂一句傻逼 表面若无其事',\n",
       " '不和他bb',\n",
       " '我会不做声，随后在背后攻击这个人',\n",
       " '反对意见',\n",
       " '今天发生的引起情绪波动的',\n",
       " '隐私',\n",
       " '方案不可行，麻烦，诸如此类。',\n",
       " '不知道',\n",
       " '挽回一个人',\n",
       " '睡一整天',\n",
       " '有钱',\n",
       " '找回失去的人',\n",
       " '将他们变成我想要的样子',\n",
       " '不好意思说',\n",
       " '宅在家玩电玩',\n",
       " '宰了马云',\n",
       " '没有过生日的习惯',\n",
       " '别人的质疑和要求给出理论依据',\n",
       " '在正规的卖票地方买票',\n",
       " '接触之后如果没有问题就买票',\n",
       " '我肯定会像一个人有礼貌的说声谢谢，并用不爽的眼神看向那个有点挑衅的人。',\n",
       " '我会再看看别的公司',\n",
       " '挑衅',\n",
       " '到正规的地方渠道去买',\n",
       " '见机行事，有些态度太好的人反而有鬼',\n",
       " '买那个挑衅的，因为另外一个有可能是假票…',\n",
       " '买贵的',\n",
       " '不卖 自己坐',\n",
       " '被说不好用',\n",
       " '咨询已买票的游客再做选择',\n",
       " '好看 壮观....挤？',\n",
       " '挺美的～要是有人陪就更好了',\n",
       " '我觉得爱人应该在身边',\n",
       " '无聊',\n",
       " '很惆怅',\n",
       " '很多人',\n",
       " '是得有多凄凉才会除夕夜一个人看烟火',\n",
       " '挺好的  但也许很多人   可以选择在居住的地方看',\n",
       " '与其他组员的想法差别较大被反驳',\n",
       " '怕被反对却只能无言以对，最后观点被驳回',\n",
       " '反对',\n",
       " '與自己意見完全相反的意見',\n",
       " '不切合实际？异想天开',\n",
       " '可能会被拒绝，可能会被改良',\n",
       " '被否决',\n",
       " '不一样的意见，但是有重叠的部分',\n",
       " '反对',\n",
       " '冲突',\n",
       " '需要修改或纳取',\n",
       " '自然会被怼',\n",
       " '矛盾',\n",
       " '遇到与自己意见相反的意见',\n",
       " '？不太懂',\n",
       " '被反对或者质疑',\n",
       " '反对意见',\n",
       " '反对',\n",
       " '小组意见争执',\n",
       " '被接受或反驳',\n",
       " '什么问题啊...',\n",
       " '没理解题目',\n",
       " '反对意见',\n",
       " '可能不会被接纳，其他组员有意见',\n",
       " '太难完成',\n",
       " '大概会遇上一些奇奇怪怪的问题？（我怎么知道）',\n",
       " '冲突？',\n",
       " '被拒绝',\n",
       " '没看到',\n",
       " '自保',\n",
       " '无为而治',\n",
       " '开始口头攻击',\n",
       " '让他学习',\n",
       " '拼了',\n",
       " '呜呜呜呜呜呜呜呜呜',\n",
       " '离开梦境',\n",
       " '诈死，装死然后偷偷拿走',\n",
       " '抱着东西夺路而逃，然后求救',\n",
       " '会遇到反驳',\n",
       " '扑上去接住，逃走',\n",
       " '斗智',\n",
       " '打爆他',\n",
       " '用我的生命',\n",
       " '我会醒来',\n",
       " '不抢救',\n",
       " '带着这个东西跑掉',\n",
       " '谈判',\n",
       " '变成这个东西',\n",
       " '扛下伤害',\n",
       " '反对我的意见',\n",
       " '引开注意力',\n",
       " '阿瓦达索命咒',\n",
       " '吸引那个巨怪的注意力，让它摔其他东西',\n",
       " '骗他还是要靠自己',\n",
       " '杀死校长',\n",
       " '劝说',\n",
       " '跪下来求他',\n",
       " '设下保护罩',\n",
       " '复印',\n",
       " '不知道',\n",
       " '不知道',\n",
       " '醒过来',\n",
       " '抱住他的大腿',\n",
       " '转移他的注意力',\n",
       " '把他们带走',\n",
       " '转移巨怪注意力',\n",
       " '悄咪咪的在它底下过去',\n",
       " '让给他',\n",
       " '用魔力去抢救',\n",
       " '可能转移注意力之类的？？',\n",
       " '自杀']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify integrity of original data\n",
    "len(train_texts_orig)\n",
    "train_texts_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用tensorflow的keras接口来建模\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, GRU, Embedding, LSTM, Bidirectional\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**分词和tokenize**  \n",
    "首先我们去掉每个样本的标点符号，然后用jieba分词，jieba分词返回一个生成器，没法直接进行tokenize，所以我们将分词结果转换成一个list，并将它索引化，这样每一例评价的文本变成一段索引数字，对应着预训练词向量模型中的词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\EdiC\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.974 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "# 进行分词和tokenize\n",
    "# train_tokens是一个长list，其中含有多个小list，对应每一条评价\n",
    "train_tokens = []\n",
    "for text in train_texts_orig:\n",
    "    # 去掉标点\n",
    "    text = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\",text)\n",
    "    # 结巴分词\n",
    "    cut = jieba.cut(text)\n",
    "    # 结巴分词的输出结果为一个生成器\n",
    "    # 把生成器转换为list\n",
    "    cut_list = [ i for i in cut ]\n",
    "    for i, word in enumerate(cut_list):\n",
    "        try:\n",
    "            # 将词转换为索引index\n",
    "            cut_list[i] = cn_model.vocab[word].index\n",
    "        except KeyError:\n",
    "            # 如果词不在字典中，则输出0\n",
    "            cut_list[i] = 0\n",
    "    train_tokens.append(cut_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**索引长度标准化**  \n",
    "因为每段评语的长度是不一样的，我们如果单纯取最长的一个评语，并把其他评填充成同样的长度，这样十分浪费计算资源，所以我们取一个折衷的长度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获得所有tokens的长度\n",
    "num_tokens = [len(tokens) for tokens in train_tokens]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.950455005055612"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 平均tokens的长度\n",
    "np.mean(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 最长的评价tokens的长度\n",
    "np.max(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log(num_tokens), bins = 100)\n",
    "plt.xlim((0,5))\n",
    "plt.ylabel('number of tokens')\n",
    "plt.xlabel('length of tokens')\n",
    "plt.title('Distribution of tokens length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取tokens平均值并加上两个tokens的标准差，\n",
    "# 假设tokens长度的分布为正态分布，则max_tokens这个值可以涵盖95%左右的样本\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9534883720930233"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取tokens的长度为236时，大约95%的样本被涵盖\n",
    "# 我们对长度不足的进行padding，超长的进行修剪\n",
    "np.sum( num_tokens < max_tokens ) / len(num_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**反向tokenize**  \n",
    "我们定义一个function，用来把索引转换成可阅读的文本，这对于debug很重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用来将tokens转换为文本\n",
    "def reverse_tokens(tokens):\n",
    "    text = ''\n",
    "    for i in tokens:\n",
    "        if i != 0:\n",
    "            text = text + cn_model.index2word[i]\n",
    "        else:\n",
    "            text = text + ' '\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse = reverse_tokens(train_tokens[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'干了一番惊天动地的事情但最后回归宁静满足死而无憾'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 经过tokenize再恢复成文本\n",
    "# 可见标点符号都没有了\n",
    "reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'干了一番惊天动地的事情，但最后回归宁静，满足，死而无憾'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 原始文本\n",
    "train_texts_orig[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**准备Embedding Matrix**  \n",
    "现在我们来为模型准备embedding matrix（词向量矩阵），根据keras的要求，我们需要准备一个维度为$(numwords, embeddingdim)$的矩阵，num words代表我们使用的词汇的数量，emdedding dimension在我们现在使用的预训练词向量模型中是300，每一个词汇都用一个长度为300的向量表示。  \n",
    "注意我们只选择使用前100k个使用频率最高的词，在这个预训练词向量模型中，一共有260万词汇量，如果全部使用在分类问题上会很浪费计算资源，因为我们的训练样本很小，一共只有4k，如果我们有100k，200k甚至更多的训练样本时，在分类问题上可以考虑减少使用的词汇量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 只使用前100000个词\n",
    "num_words = 100000\n",
    "# 初始化embedding_matrix，之后在keras上进行应用\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "# embedding_matrix为一个 [num_words，embedding_dim] 的矩阵\n",
    "# 维度为 100000 * 300\n",
    "for i in range(num_words):\n",
    "    embedding_matrix[i,:] = cn_model[cn_model.index2word[i]]\n",
    "embedding_matrix = embedding_matrix.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 检查index是否对应，\n",
    "# 输出300意义为长度为300的embedding向量一一对应\n",
    "np.sum( cn_model[cn_model.index2word[333]] == embedding_matrix[333] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding_matrix的维度，\n",
    "# 这个维度为keras的要求，后续会在模型中用到\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**padding（填充）和truncating（修剪）**  \n",
    "我们把文本转换为tokens（索引）之后，每一串索引的长度并不相等，所以为了方便模型的训练我们需要把索引的长度标准化，上面我们选择了236这个可以涵盖95%训练样本的长度，接下来我们进行padding和truncating，我们一般采用'pre'的方法，这会在文本索引的前面填充0，因为根据一些研究资料中的实践，如果在文本索引后面填充0的话，会对模型造成一些不良影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行padding和truncating， 输入的train_tokens是一个list\n",
    "# 返回的train_pad是一个numpy array\n",
    "train_pad = pad_sequences(train_tokens, maxlen=max_tokens,\n",
    "                            padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超出五万个词向量的词用0代替\n",
    "train_pad[train_pad>=num_words] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 926, 769,\n",
       "       156,  12])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可见padding之后前面的tokens全变成0，文本在最后面\n",
    "train_pad[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准备target向量，前641样本为1，后348为0\n",
    "train_target = np.concatenate((np.ones(641),np.zeros(348)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行训练和测试样本的分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90%的样本用来训练，剩余10%用来测试\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_pad, train_target, test_size=0.1, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            有意思的一生\n",
      "class:  1.0\n"
     ]
    }
   ],
   "source": [
    "# 查看训练样本，确认无误\n",
    "print(reverse_tokens(X_train[15]))\n",
    "print('class: ',y_train[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们用keras搭建LSTM模型，模型的第一层是Embedding层，只有当我们把tokens索引转换为词向量矩阵之后，才可以用神经网络对文本进行处理。\n",
    "keras提供了Embedding接口，避免了繁琐的稀疏矩阵操作。   \n",
    "在Embedding层我们输入的矩阵为：$$(batchsize, maxtokens)$$\n",
    "输出矩阵为： $$(batchsize, maxtokens, embeddingdim)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement K-fold validation, k=4\n",
    "# k = 4\n",
    "# num_val_samples = len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用LSTM对样本进行分类\n",
    "model = Sequential()\n",
    "\n",
    "# 模型第一层为Embedding\n",
    "model.add(Embedding(num_words,\n",
    "                    embedding_dim,\n",
    "                    weights=[embedding_matrix],\n",
    "                    input_length=max_tokens,\n",
    "                    trainable=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Bidirectional(LSTM(units=32, return_sequences=True)))\n",
    "model.add(LSTM(units=16, return_sequences=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**构建模型**  \n",
    "我在这个教程中尝试了几种神经网络结构，因为训练样本比较少，所以我们可以尽情尝试，训练过程等待时间并不长：  \n",
    "**GRU：**如果使用GRU的话，测试样本可以达到87%的准确率，但我测试自己的文本内容时发现，GRU最后一层激活函数的输出都在0.5左右，说明模型的判断不是很明确，信心比较低，而且经过测试发现模型对于否定句的判断有时会失误，我们期望对于负面样本输出接近0，正面样本接近1而不是都徘徊于0.5之间。  \n",
    "**BiLSTM：**测试了LSTM和BiLSTM，发现BiLSTM的表现最好，LSTM的表现略好于GRU，这可能是因为BiLSTM对于比较长的句子结构有更好的记忆，有兴趣的朋友可以深入研究一下。  \n",
    "Embedding之后第，一层我们用BiLSTM返回sequences，然后第二层16个单元的LSTM不返回sequences，只返回最终结果，最后是一个全链接层，用sigmoid激活函数输出结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRU的代码\n",
    "# model.add(GRU(units=32, return_sequences=True))\n",
    "# model.add(GRU(units=16, return_sequences=True))\n",
    "# model.add(GRU(units=4, return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# 我们使用adam以0.001的learning rate进行优化\n",
    "optimizer = Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 15, 300)           30000000  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 15, 64)            85248     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 16)                5184      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 30,090,449\n",
      "Trainable params: 90,449\n",
      "Non-trainable params: 30,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 模型的结构\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立一个权重的存储点\n",
    "path_checkpoint = 'sentiment_checkpoint.keras'\n",
    "checkpoint = ModelCheckpoint(filepath=path_checkpoint, monitor='val_loss',\n",
    "                                      verbose=1, save_weights_only=True,\n",
    "                                      save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 尝试加载已训练模型\n",
    "try:\n",
    "    model.load_weights(path_checkpoint)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义early stoping如果3个epoch内validation loss没有改善则停止训练\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自动降低learning rate\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                       factor=0.1, min_lr=1e-5, patience=0,\n",
    "                                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义callback函数\n",
    "callbacks = [\n",
    "    earlystopping, \n",
    "    checkpoint,\n",
    "    lr_reduction\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 801 samples, validate on 89 samples\n",
      "Epoch 1/20\n",
      "800/801 [============================>.] - ETA: 0s - loss: 0.2540 - acc: 0.9075\n",
      "Epoch 00001: val_loss did not improve from 0.47135\n",
      "801/801 [==============================] - 2s 2ms/sample - loss: 0.2537 - acc: 0.9076 - val_loss: 0.5274 - val_acc: 0.7528\n",
      "Epoch 2/20\n",
      "800/801 [============================>.] - ETA: 0s - loss: 0.2537 - acc: 0.9062\n",
      "Epoch 00002: val_loss did not improve from 0.47135\n",
      "801/801 [==============================] - 1s 2ms/sample - loss: 0.2535 - acc: 0.9064 - val_loss: 0.5285 - val_acc: 0.7528\n",
      "Epoch 3/20\n",
      "800/801 [============================>.] - ETA: 0s - loss: 0.2534 - acc: 0.9050\n",
      "Epoch 00003: val_loss did not improve from 0.47135\n",
      "801/801 [==============================] - 1s 2ms/sample - loss: 0.2532 - acc: 0.9051 - val_loss: 0.5289 - val_acc: 0.7528\n",
      "Epoch 4/20\n",
      "800/801 [============================>.] - ETA: 0s - loss: 0.2533 - acc: 0.9050\n",
      "Epoch 00004: val_loss did not improve from 0.47135\n",
      "801/801 [==============================] - 1s 2ms/sample - loss: 0.2530 - acc: 0.9051 - val_loss: 0.5291 - val_acc: 0.7528\n",
      "Epoch 00004: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1adbec75f60>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "          validation_split=0.1, \n",
    "          epochs=20,\n",
    "          batch_size=32,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**结论**  \n",
    "我们首先对测试样本进行预测，得到了还算满意的准确度。  \n",
    "之后我们定义一个预测函数，来预测输入的文本的极性，可见模型对于否定句和一些简单的逻辑结构都可以进行准确的判断。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99/99 [==============================] - 0s 576us/sample - loss: 0.5700 - acc: 0.7273\n",
      "Accuracy:0.72727275\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test, y_test)\n",
    "print('Accuracy:'+str(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    print(text)\n",
    "    # 去标点\n",
    "    text = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\",text)\n",
    "    # 分词\n",
    "    cut = jieba.cut(text)\n",
    "    cut_list = [ i for i in cut ]\n",
    "    # tokenize\n",
    "    for i, word in enumerate(cut_list):\n",
    "        try:\n",
    "            cut_list[i] = cn_model.vocab[word].index\n",
    "        except KeyError:\n",
    "            cut_list[i] = 0\n",
    "    # padding\n",
    "    tokens_pad = pad_sequences([cut_list], maxlen=max_tokens,\n",
    "                           padding='pre', truncating='pre')\n",
    "    # 预测\n",
    "    result = model.predict(x=tokens_pad)\n",
    "    coef = result[0][0]\n",
    "    if coef >= 0.5:\n",
    "        print('是一例正面评价','output=%.2f'%coef)\n",
    "    else:\n",
    "        print('是一例负面评价','output=%.2f'%coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我觉得不好\n",
      "是一例负面评价 output=0.15\n",
      "我觉得很好\n",
      "是一例正面评价 output=0.96\n",
      "我被孤立了\n",
      "是一例负面评价 output=0.08\n",
      "我的心情有时候好，有时候不好\n",
      "是一例负面评价 output=0.13\n",
      "我很孤独\n",
      "是一例负面评价 output=0.12\n",
      "陈子迅\n",
      "是一例正面评价 output=0.59\n",
      "尹俊杰\n",
      "是一例正面评价 output=0.95\n"
     ]
    }
   ],
   "source": [
    "test_list = [\n",
    "    '我觉得不好',\n",
    "    '我觉得很好',\n",
    "    '我被孤立了',\n",
    "    '我的心情有时候好，有时候不好',\n",
    "    '我很孤独',\n",
    "    '陈子迅',\n",
    "    '尹俊杰'\n",
    "]\n",
    "for text in test_list:\n",
    "    predict_sentiment(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**错误分类的文本**\n",
    "经过查看，发现错误分类的文本的含义大多比较含糊，就算人类也不容易判断极性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.T[0]\n",
    "y_pred = [1 if p>= 0.5 else 0 for p in y_pred]\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 找出错误分类的索引\n",
    "misclassified = np.where(y_pred != y_actual)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "# 输出所有错误分类的索引\n",
    "len(misclassified)\n",
    "print(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           选诚恳的人\n",
      "预测的分类 1\n",
      "实际的分类 1.0\n"
     ]
    }
   ],
   "source": [
    "# 找出错误分类的样本\n",
    "idx=3\n",
    "print(reverse_tokens(X_test[idx]))\n",
    "print('预测的分类', y_pred[idx])\n",
    "print('实际的分类', y_actual[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            氪金打游戏\n",
      "预测的分类 1\n",
      "实际的分类 0.0\n"
     ]
    }
   ],
   "source": [
    "idx=1\n",
    "print(reverse_tokens(X_test[idx]))\n",
    "print('预测的分类', y_pred[idx])\n",
    "print('实际的分类', y_actual[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
